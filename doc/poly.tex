%% The openany option is here just to remove the blank pages before a new chapter
\documentclass[11pt,openany]{book}

\title{Analyse syntaxique automatique du langage naturel}

\usepackage{pagenote}
\usepackage{booktabs}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{latexsym}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{tikz}
\usetikzlibrary{snakes}
\usetikzlibrary{matrix}
\usetikzlibrary{shapes}
\usepackage{comment}
\usepackage{minted}



\newtheorem{definition}{Définition}[chapter]
\newtheorem{exo}{Exercice}[chapter]
\includecomment{solution}
%\excludecomment{solution}


%%%%%%%%%%%%% For customising the endnote markers. Comment these out if you don't want them.
% To prefix each note number with the chapter number
\renewcommand{\thepagenote}{\thechapter-\arabic{pagenote}}

% To have a slightly different formatting for the endnote numbers in the text -- smaller text, sans-serif, square brackets
\renewcommand\notenumintext[1]{\space{\footnotesize\sffamily[FN-#1]}}

% To have a slightly different formatting for the endnote numbers in the notes section. Just the square brackets and sans-serif; normal size.
\renewcommand\notenuminnotes[1]{{\sffamily[FN-#1] }}

% If you want a different name/heading for the end notes
\renewcommand{\notesname}{End Notes}
%%%%%%%%%%%%% End customisation


%% THIS LINE IS MANDATORY
\makepagenote

\usepackage{hyperref}
\usepackage{tikz}

\newcommand{\ac}[1]{{\sc #1}} %acronym
\newcommand{\kw}[1]{{\bf #1}} %keyword

\begin{document}


\chapter*{Notations}

\url{http://www-users.cs.umn.edu/~karypis/parbook/Lectures/AG/chap12_slides.pdf}
\url{http://www.aclweb.org/anthology/C08-5001}
\url{http://www.cs.columbia.edu/~mcollins/}

\paragraph{Pseudo Code}
\begin{description}
\item $X|Y$ concatène les listes $X$ et $Y$
\item $x_i$ le $i$-ème élément de la liste $X$
\item $_{\ominus}X$ la liste $X$ sans son premier élément
\item $X_{\ominus}$ la liste $X$ sans son dernier élément
\end{description}
 

\chapter{Aspects algorithmiques}

\section{Prédiction de séquences}
Un nombre important de problèmes de traitement automatique des langues (\ac{Tal}) peuvent se formaliser comme des problèmes de recherche de chemin le plus long (ou parfois le plus court) dans un graphe acyclique orienté (\ac{Dag}).

Un exemple intuitif est le problème d'étiquetage de séquences appelé étiquetage morphosyntaxique. \'{E}tant donnée une séquence de $n$ mots $w_1\ldots w_n$,  on se donne pour tâche de prédire leurs parties de discours $t_1\ldots t_n$. 

En première approche, on peut considérer deux méthodes pour  étiqueter des séquences de mots~: d'une part on peut envisager étiqueter chaque mot $w_i$ par une étiquette $t_i$ en fonction du contexte $C$ où il apparaît à l'aide d'une fonction $f: W, C \mapsto T$ (où $W$ dénote un ensemble de mots, $C$ un ensemble de contextes\footnote{Typiquement un élément de $C$ sera un tuple de mots qui sont situés à gauche et à droite de $w_i$} et $T$ un ensemble de parties de discours). La première approche met en jeu  un {\bf modèle local} qui prédit  chacune des étiquettes $t_i$ indépendamment de toute autre étiquette $t_j\, (i\not = j)$.

L'approche alternative, dite globale et qui fait intervenir un {\bf modèle structuré} cherche à prédire la séquence de tags $t_1\ldots t_n$ en une fois.  La fonction de prédiction est de la forme $f:W^n \mapsto T^n$, autrement dit elle envoie une séquence de $n$ mots sur des séquences d'étiquettes de $n$ tags.  Utiliser cette seconde alternative  revient à supposer que les séquences forment une structure intéressante pour la prédiction. Ainsi un modèle local
peut faire des erreurs pour prédire le tag $t_i$ qui sont liées à l'ignorance des prédictions 
faites pour les tags avoisinants (comme par exemple $t_{i-1},t_{i-2}$\ldots). 

\begin{center}
\begin{tabular}{ccc}\toprule
\multicolumn{3}{c}{Prédiction globale ?}\\\midrule
D & A & N\\
Le & grand & est\\\bottomrule
\end{tabular}
\begin{tabular}{ccc}\toprule
\multicolumn{3}{c}{Prédiction locale ?}\\\midrule
D & A & {\bf\color{red} V}\\
Le & grand & est\\\bottomrule
\end{tabular}
\end{center}

Le problème de prédiction globale ou structurée est plus complexe que le problème de prédiction locale. En effet pour un jeu de tags $T$ un modèle local doit choisir $n$ fois parmi $|T|$ alternatives pour étiqueter une phrase,  alors qu'un modèle global doit choisir parmi un ensemble de $|T|^n$ alternatives, ce qui a un coût~: réaliser ce choix naïvement demande d'enumérer un ensemble  exponentiel d'alternatives d'étiquetages de la phrase.

\paragraph{Fonction de pondération}
Réaliser le tagging d'une séquence de mots $\mathbf{w} =  w_1\ldots w_n$ demande de choisir une séquence de tags $\mathbf{t} = t_1\ldots t_n \in T^n$. 
Ce  choix s'appuie en général sur une \kw{fonction de pondération} $\sigma : T^n\times W^n \mapsto \mathbb{R}$ qui associe un score à toute séquence de tags.
La méthode de pondération permet alors d'ordonner les différentes séquences de tags en fonction du score qui leur est associé.  La \kw{fonction de décision} réalise le choix de la séquence à préférer en utilisant souvent une forme du type :
\begin{equation}
\label{eq-decision}
\hat{\mathbf{t}} = \mathop{\text{argmax}}_{\mathbf{t} \in T^n}\quad \sigma(\mathbf{t},\mathbf{w})
\end{equation}
Généralement la fonction de pondération est instanciée par une méthode d'apprentissage automatique. Indiquons également que le calcul de la solution de (\ref{eq-decision})  consiste essentiellement à résoudre un \kw{problème d'optimisation} de la forme :
\begin{equation}
\label{eq-combi-optim}
m = \mathop{\text{max}}_{\mathbf{t} \in T^n}\quad \sigma(\mathbf{t},\mathbf{w})
\end{equation}
à partir de là on tire généralement la solution de (\ref{eq-decision}) 
par effet de bord.

Ce qui distingue \ref{eq-combi-optim} d'un problème d'optimisation classique,
c'est qu'il s'agit de chercher une valeur optimale dans un ensemble énumérable de taille finie dont les valeurs sont structurées en séquences.
Bien que de taille finie, l'ensemble des solutions est en général de taille considérable de telle sorte qu'une méthode de recherche de solutions qui consiste à énumérer exhaustivement chacune des solutions est en général inutilisable.


\section{Arbre de recherche de solutions}
\marginpar{Biblio (AIMA : a modern approach)}

La recherche de solutions à des problèmes de type (\ref{eq-combi-optim}) 
peut s'exprimer sous la forme générale d'un problème de recherche~:
\begin{itemize}
\item Un espace de recherche qui est un ensemble $Q$ d'états
\item Un état initial $q_0 \in Q$ qui est l'état à partir duquel le tagger commence.    
\item Un ensemble $F\subseteq Q$ d'états finaux qui indique les états dans lequel le tagger a terminé.
\item Un ensemble $A$ d'actions, dans le cas d'un tagger la seule action possible est de tagguer le mot suivant. On définit un ensemble d'actions $A$ pour lequel chaque élément représente l'attribution d'un tag au mot suivant dans la phrase.
\item Un ensemble $T\subseteq Q\times Q \times A$ de transitions qui induit une structure d'arbre.
\item Une fonction de coût $\sigma$ ou de score qui représente le score d'une séquence d'états calculé depuis l'état initial. On suppose que toute transition  $(q_i,q_{i+1},a_i) \in T$ se voit attribuer un coût $\psi(q_i,q_{i+1},a_i)$ par une fonction $\psi: T \mapsto \mathbb{R}$. On pose par convention que le coût de la séquence de transitions qui mène à l'état $q_k$ est le produit des coûts des transitions qui la composent~: 
\begin{displaymath}
\sigma(q_k) = \bigotimes_{0\leq i < k} \psi(q_i,q_{i+1},a_i)
\end{displaymath}
\end{itemize}
\begin{figure}[htbp]
\begin{tikzpicture}[xscale=2,yscale=2]

    \node[shape=circle,draw=black,double=red] (S) at (0,3) {S};
     \node[shape=circle,draw=black,double=red] (E) at (6,3) {E};


    \node[shape=circle,draw=black] (A1) at (1,1) {D};
    \node[shape=circle,draw=black] (B1) at (1,2) {N};
    \node[shape=circle,draw=black] (C1) at (1,3) {A};
    \node[shape=circle,draw=black] (D1) at (1,4) {P};
    \node[shape=circle,draw=black] (E1) at (1,5) {V};

 \draw [opacity=0.5](B1.east) -- (1.5,1.6) -- (1.5,2.4) -- cycle;
 \draw [opacity=0.5](C1.east) -- (1.5,3.4) -- (1.5,2.6) -- cycle;
 \draw [opacity=0.5](D1.east) -- (1.5,4.4) -- (1.5,3.6) -- cycle;
 \draw [opacity=0.5](E1.east) -- (1.5,5.4) -- (1.5,4.6) -- cycle;
 
    \node[shape=circle,draw=black] (A2) at (2,-1){D};
    \node[shape=circle,draw=black] (B2) at (2,0) {N};
    \node[shape=circle,draw=black] (C2) at (2,1) {A};
    \node[shape=circle,draw=black] (D2) at (2,2) {P};
    \node[shape=circle,draw=black] (E2) at (2,3) {V};

     \draw [opacity=0.5](A2.east) -- (2.5,-1.4) -- (2.5,-0.6) -- cycle;
     \draw [opacity=0.5](B2.east) -- (2.5,0.4) -- (2.5,-0.4) -- cycle;
     \draw [opacity=0.5](C2.east) -- (2.5,0.6) -- (2.5,1.4) -- cycle;
      \draw [opacity=0.5](D2.east) -- (2.5,2.4) -- (2.5,1.6) -- cycle;
       \draw [opacity=0.5](E2.east) -- (2.5,3.4) -- (2.5,2.6) -- cycle;
     
      \draw [->,decorate,decoration={snake,amplitude=.8mm,segment length=2mm,post length=1mm},opacity=0.5](2,5)  --  (E.west);
      \draw [->,decorate,decoration={snake,amplitude=.8mm,segment length=2mm,post length=1mm},opacity=0.5](3,3)  --  (E.west);
      \draw [->,decorate,decoration={snake,amplitude=.8mm,segment length=2mm,post length=1mm},opacity=0.5](3,-1)  --  (E.west);

	 \draw [->,ultra thick,opacity=0.5] (S) -- (A1);
	 \draw [->,opacity=0.5] (S) -- (B1);
	 \draw [->,opacity=0.5] (S) -- (C1);
	 \draw [->,opacity=0.5] (S) -- (D1);
	 \draw [->,opacity=0.5] (S) -- (E1);

     \draw [->,opacity=0.5] (A1) -- (A2);
	 \draw [->,opacity=0.5] (A1) -- (B2);
	 \draw [->,ultra thick,opacity=0.5] (A1) -- (C2);
	 \draw [->,opacity=0.5] (A1) -- (D2);
	 \draw [->,opacity=0.5] (A1) -- (E2);



 \node[draw=white,text depth=0.25ex,text height=1cm] (W1) at (1,-2) {La} ;
    \node[draw=white,text depth=0.25ex,text height=1cm] (W2) at (2,-2) {belle} ;
    \node[draw=white,text depth=0.25ex,text height=1cm] (W3) at (3,-2) {porte} ;
    \node[draw=white,text depth=0.25ex,text height=1cm] (W4) at (4,-2) {le} ;
    \node[draw=white,text depth=0.25ex,text height=1cm] (W5) at (5,-2) {cache} ;

\end{tikzpicture}
\caption{\label{fig-searchtree}Arbre de recherche de solutions}
\end{figure}
On peut illustrer la  structure d'un problème de recherche par un arbre comme en figure \ref{fig-searchtree} pour un problème d'étiquetage morphosyntaxique (les scores sont omis). En fait un nombre très important de problèmes de \ac{tal} peut s'analyser en termes de problème de recherche de solutions dans de grands ensembles à valeurs structurées. On verra qu'on peut ainsi définir des variantes quant à la nature des états, du système de transition, des actions et que la fonction de coût dépend en général de la méthode d'apprentissage utilisée. 
\begin{algorithm}[htbp]
\begin{algorithmic}[1]
\Function{MaxSearch}{S,B,$\sigma$}
\If{$B \not = \epsilon$}
\State maxscore $\gets \bar{0}$
\ForAll{$t \in T$}
	\State pscore $\gets \sigma \otimes \psi(S,B,t)$
	\State maxscore $\gets $\Call{$\oplus$}{}(maxscore,\Call{MaxSearch}{$S|t$,$_{\ominus}$B,pscore})
\EndFor
\State\Return maxscore
\Else
  \State\Return $\sigma$
\EndIf
\EndFunction
\end{algorithmic}
\caption{\label{algo-searchtree}Algorithme de recherche structuré en arbre (cas du tagger)}
\end{algorithm}
En principe, quand l'arbre de recherche a une taille raisonnable, l'exploration des solutions peut se faire exhaustivement.  Mais en pratique cette première solution est en général utilisée rarement telle quelle~: on utilise plutôt des méthodes de programmation dynamique, de recherche approximative ou une combinaison des deux.

On  donne en algorithme \ref{algo-searchtree},
un exemple d'algorithme de recherche pour un problème structuré en arbre. On peut notamment constater que la structure d'arbre de recherche n'est pas exprimée par une structure de donnée explicite mais plutôt implicitement par la structure d'appels récursifs du programme. Comme exercice, il peut être intéressant de repérer les différentes composantes du problème de recherche dans le pseudo-code  (Algorithme \ref{algo-searchtree}).



\begin{exo}Réécrire l'algorithme de parcours d'arbre de recherche
pour que le résultat renvoyé soit maintenant un couple qui comporte la valeur de score maximale mais aussi la séquence de tags correspondante
\end{exo}






\section{Systèmes de transition}

Pour spécifier explicitement un problème de recherche de solutions en \ac{tal}, on utilise fréquemment une spécification sous forme de système de transitions. Ce type de spécification a été popularisé par la tâche d'analyse syntaxique en dépendances.  Mais celle-ci est très générale, on trouve ce type de systèmes également pour spécifier des problèmes de planification en intelligence artificielle et (parfois) des méthodes de démonstration automatique. 

On propose de les introduire immédiatement par un premier exemple qui caractérise explicitement une tâche de tagging. Spécifier un système de transitions revient à spécifier chacun des éléments suivants~:
\begin{itemize}
\item L'ensemble $Q$ des états est structuré. Chaque état $q\in Q$ est un couple $(S,B)$ où $S$ est une séquence de tags déjà prédits et $B$ une séquence de mots encore à traiter dans la phrase. 
\item L'état initial $q_0$ est l'état $(\epsilon , B)$ où $B$ est la liste des mots de la phrase à étiqueter.
\item L'ensemble des états finaux est l'ensemble $F$ des états tels que $B$ est vide. 
\item L'ensemble $A$ des actions est l'ensemble qui représente le jeu de tags $t\in A$ utilisé par le tagger.
\item L'ensemble $T$ des transitions est la relation
entre états qui satisfait le critère suivant~: 
\begin{displaymath}
(S,b_0|B) \stackrel{t}{\Rightarrow}(S|t,B)\qquad (t \in A)
\end{displaymath}
Ce qui signifie que le premier mot de $B$ est enlevé; le tag qui correspond à l'action exécutée est ajouté à $S$.
\item Le coût local d'une transition $\psi(S,B,t)$ est calculé par un modèle d'apprentissage approprié. 
\end{itemize}

Notons que les systèmes de transitions peuvent servir à exprimer des automates et des transducteurs à nombre finis d'états ou des contreparties d'automates à pile. Mais il est commun en \ac{tal} de ne pas limiter l'usage des systèmes de transition au seul encodage de ce type de machines.

\begin{exo}
Définir une variante de ce système de transition qui permet à un tagger d'accéder également aux mots qui précèdent dans la phrase avec la fonction de score $\psi(S,B,t)$ ou une de ses variantes. 
\end{exo}
\begin{exo}
Réécrire l'algorithme de parcours d'un arbre de recherche pour qu'il renvoie le poids de la solution de poids maximal à l'aide du système de transitions donné ci-dessus.
\end{exo}
\begin{solution}
\begin{algorithmic}
\Function{MaxSearch}{S,B,$\sigma$}
\If {B $\not = \epsilon$}
\State maxscore $\gets \bar{0}$
\ForAll{$t \in A$}
\State pscore $\gets \sigma \otimes \psi(S,B,t)$ 
\State maxscore $\gets$ \Call{$\oplus$}{}(maxscore,\Call{MaxSearch}{$S|t$,$_\ominus B$,pscore})
\EndFor
\State\Return maxscore
\Else
\State\Return $\sigma$
\EndIf
\EndFunction
\end{algorithmic}
\end{solution}
\begin{exo}
Modifier la formulation de l'exercice précédent pour faire en sorte qu'il renvoie la séquence de tags ainsi que le poids de cette solution
\end{exo}

Lorsque l'espace des solutions est trop grand (ce qui est généralement le cas pour la plupart des problèmes de \ac{tal}) l'algorithme naïf de recherche vu jusqu'à présent, qui a une complexité exponentielle en $\mathcal{O}(A^n)$ est inutilisable. On se tourne alors vers des solutions qui s'appuient sur de la programmation dynamique (Section \ref{sec-DP}) ou des solutions  de recherche approximative ou une combinaison des deux.




\section{Programmation dynamique}
\label{sec-DP}
Une des faiblesses de l'algorithme de recherche de solutions
vu jusqu'à présent est qu'il réplique une quantité très importante de calculs.
Pour nous en rendre compte, considérons deux séquences de tags 
\begin{center}
\begin{tabular}{ccccc}\toprule
D &A& N& D& V\\
D& A& N& P& V\\\midrule
La&belle&porte&le&cache\\\bottomrule
\end{tabular}
\end{center}
qui diffèrent par un élément.  On constate qu'une méthode de recherche en arbre (qui procède ici de droite à gauche)  va recalculer au moins deux foix la valeur du préfixe {\sl D A N}.  De manière générale la méthode de recherche de solutions en arbre reduplique une quantité considérable de calculs de préfixes, ce qui est largement inefficace.
\begin{center}
\begin{tikzpicture}[xscale=1.75,yscale=1.75]

\node[shape=circle,draw=black,double=red] (S) at (0,0) {S};
\node[shape=circle,draw=black,double=red] (E) at (6,0) {E};
\node[shape=circle,draw=black] (A1) at (5,0) {V};
\node[shape=circle,draw=black] (A2) at (4,-1) {P};
\node[shape=circle,draw=black] (B2) at (4,1) {D};
\node[shape=circle,fill=red,fill opacity=0.2,draw=black] (C2) at (3,-1) {N};
\node[shape=circle,fill=red,fill opacity=0.2,draw=black] (C1) at (3,1) {N};
\draw [->,opacity=0.5](E) -- (A1);
\draw [->,opacity=0.5](A1) -- (A2);
\draw [->,opacity=0.5](A1) -- (B2);
\draw [->,opacity=0.5](A2) -- (C2);
\draw [->,opacity=0.5](B2) -- (C1);
\draw [->,opacity=0.5, decorate,decoration={snake,amplitude=.2mm,segment length=2mm,post length=1mm}] (C1) -- (S.east);
\draw [->,opacity=0.5, decorate,decoration={snake,amplitude=.2mm,segment length=2mm,post length=1mm}] (C2) -- (S.east);
\end{tikzpicture}
\end{center}
L'idée des méthodes de \kw{programmation dynamique}, c'est d'éviter les reduplications de calculs inutiles pour réutiliser des résultats intermédiaires (partage de calcul). Ainsi l'espace des états est organisé en  graphe (\ac{dag}) plutôt qu'en arbre. Cette nouvelle organisation permet de proposer des solutions algorithmiques en temps polynomial plutôt qu'en temps exponentiel aux problèmes de recherche qui nous concernent.

\begin{center}
\begin{tikzpicture}[xscale=1.75,yscale=1.75]

\node[shape=circle,draw=black,double=red] (S) at (0,0) {S};
\node[shape=circle,draw=black,double=red] (E) at (6,0) {E};
\node[shape=circle,draw=black] (A1) at (5,0) {V};
\node[shape=circle,draw=black] (A2) at (4,-1) {P};
\node[shape=circle,draw=black] (B2) at (4,1) {D};
\node[shape=circle,fill=green,fill opacity=0.2,draw=black] (C1) at (3,0) {N};
\draw [->,opacity=0.5](E) -- (A1);
\draw [->,opacity=0.5](A1) -- (A2);
\draw [->,opacity=0.5](A1) -- (B2);
\draw [->,opacity=0.5](A2) -- (C1);
\draw [->,opacity=0.5](B2) -- (C1);
\draw [->,opacity=0.5, decorate,decoration={snake,amplitude=.2mm,segment length=2mm,post length=1mm}] (C1) -- (S.east);
\end{tikzpicture}
\end{center}



\subsection{Graphe Acyclique orienté}

\begin{definition}[DAG] 
Un graphe acyclique orienté (\ac{dag}) est un graphe $G = \langle V,E \rangle$ où $V$ est un ensemble de noeuds et $E$ un ensemble d'arcs
($E \subseteq V\times V$) tel qu'il ne comporte pas de circuit.
Dans le cas pondéré, on  y ajoute une fonction $s: E \mapsto \mathbb{R}$
qui donne un score à chacun des arcs.
\end{definition}

\begin{definition}[Arc entrants] 
Soit un noeud $x\in V$, l'ensemble $AE(x) = \{(y,x) \,|\, (y,x) \in E , y \in V \}$ est l'ensemble des arcs entrants sur ce noeud. 
\end{definition}

\begin{definition}[Arc sortants] 
Soit un noeud $x\in V$, l'ensemble $AS(x) = \{(x,y) \,|\, (x,y) \in E , y \in V \}$ est l'ensemble des arcs sortants de ce noeud. 
\end{definition}

\begin{definition}[Chemin]
Un chemin de longeur $n$ est une séquence de noeuds $\pi \in V^n$ de la forme $\pi = v_1 v_2\ldots v_n$ tel que $(v_i,v_{i+1}) \in E$ pour tout $1\leq i < n$. Le score $\sigma(\pi)$ d'un chemin est le produit :
\begin{displaymath}
\sigma(\pi) = \bigotimes_{i=1}^{n-1} \psi(v_i,v_{i+1}) 
\end{displaymath}
\end{definition}

\begin{definition}[Poids maximal depuis la source]
Soit un \ac{dag} dont un noeud distingué $s\in V$ est appelé noeud source. En notant $P(x)$ l'ensemble des chemins qui mènent de la source
à $x$, on définit le poids maximal de $x$ comme suit~: 
\begin{displaymath}
\delta(x)  = \left\{ 
\begin{array}{ll}
\bar{0} & \text{si } $x = s$ \\
\bigoplus_{\pi \in P(x)} \sigma(\pi) &\text{sinon}
\end{array}
\right.
\end{displaymath}
\end{definition}


\subsection{Optimisation de fonctions récursives}
Un problème de programmation dynamique est typiquement formulé comme un problème d'optimisation entre différentes alternatives~: il s'agit par exemple de trouver un chemin de poids maximum parmi plusieurs chemins pondérés.

\begin{center}
\begin{tikzpicture}[xscale=2,yscale=2]
\node[shape=circle,draw=black,double=red] (S) at (0,0) {S};
\node[shape=circle,draw=black,double=red] (E) at (4,0) {E};
\node[shape=circle,draw=black] (1) at (1,1) {A};
\node[shape=circle,draw=black] (2) at (3,1) {C};
\node[shape=circle,draw=black] (3) at (2,0) {B};
\draw [->,opacity=0.5](S) -- (1) node[midway,fill=white]{$s(S,A)$};
\draw [->,opacity=0.5](S) -- (3) node[midway,fill=white]{$s(S,B)$};
\draw [->,opacity=0.5](1) -- (3) node[midway,fill=white]{$s(A,B)$};
\draw [->,opacity=0.5](1) -- (2) node[midway,fill=white]{$s(A,C)$};
\draw [->,opacity=0.5](3) -- (2) node[midway,fill=white]{$s(B,C)$};
\draw [->,opacity=0.5](2) -- (E) node[midway,fill=white]{$s(C,E)$};
\draw [->,opacity=0.5](3) -- (E) node[midway,fill=white]{$s(B,E)$};
\end{tikzpicture}
\end{center}

Notons $\sigma(x)$ le coût d'un chemin entre le noeud initial du \ac{dag} et un noeud $x$. En notant $x_{-1},x_{-2}\ldots x_{-k}$ les prédécesseurs d'un noeud $x$ dans le graphe ($x_{-i} \in AE(x)$), on a que le chemin de poids maximal pour arriver à $x$ depuis ses prédécesseurs est donné par l'équation :
\begin{equation}
\label{eq-bellmann}
\delta(x) = \left\{ 
\begin{array}{ll}
\bar{0} & \text{si }  x = q_0\\
\oplus \left[ \alpha(x_{-1}) \otimes \psi(x_{-1},x), \ldots ,\alpha(x_{-k}) \otimes \psi(x_{-k},x) \right] &\text{sinon}
\end{array}
\right.
\end{equation}
qui est appelée équation de programmation dynamique ou \kw{équation de Bellmann}. Il s'agit d'une formule récursive qui fait intervenir deux opérations~: $\oplus$ est une opération d'aggrégation parmi plusieurs alternatives comme typiquemen {\sl max} ou {\sl min} et $\otimes$ est un opération de composition destinée à calculer le score de chemins dans un \ac{dag} comme typiquement $+$ ou $\times$. 

La récurrence exprimée en (\ref{eq-bellmann})  indique que pour déterminer le poids du chemin optimal qui mène à $x$, il faut comparer le poids de l'ensemble des chemins qui passent par les prédécesseurs de $x$ dans le \ac{dag}.

Mais cette récurrence indique surtout que pour déterminer le coût du chemin optimal pour atteindre $x$ il faut essentiellement réutiliser la solution du sous-problème pour chacun des prédécesseurs de $x$, ce qui revient à déterminer le chemin optimal qui mène à chacun des $x_{-i}$.

Lorsque certains sous-problèmes sont à recalculer plusieurs fois, on  dit qu'il y a \kw{recouvrement de sous-problèmes}. Les techniques de programmation dynamique consistent à éviter l'évaluation multiple d'un même sous-problème en mémorisant les solutions intermédiaires.

Plusieurs techniques pour réaliser la mémorisation seront présentées mais celles-ci font généralement appel à une table dite table de programmation dynamique pour mémoriser les résultats intermédiaires. Celle-ci mémorise les valeurs $\delta(x)$ des états $x$ visités lors de la résolution du problème.

Une solution simple et directe pour exprimer ce qui précède est la technique de \kw{mémoisation}. Celle-ci repose sur l'usage de \kw{mémo-fonctions}. L'idée est de mémoriser la solution $\delta(x)$ dans une table dès que celle-ci est déterminée. Cette table est alors consultée dans les étapes ultérieures de l'algorithme de telle sorte que la valeur mémorisée est réutilisée au lieu de réexécuter l'appel récursif.

L'algorithme \ref{algo-searchMemo} illustre le principe de la mémoisation. On suppose que le \ac{dag} a un état final $q_f$, et que la table {\sl memo} est initialisée à $\delta(x) = \bar{0}$ pour tout  $x\in V$ (sauf $\delta(q_0) = \bar{1}$). La fonction est initialement appelée avec le paramètre $q_f$.  

\begin{algorithm}[htbp]
\begin{algorithmic}[1]
\Function{MaxSearchMemo}{x}
\If{$\text{memo}[x] \not = \bar{0}$}
\Comment{Score mémoisé}
\State\Return memo[x]
\EndIf
\ForAll{$y \in AE(x)$}
\State memo[x] $\gets$ \Call{$\oplus$}{}(memo[x],\Call{MaxSearchMemo}{y} $\otimes \psi(y,x)$)
\EndFor
\State\Return memo[x]
\EndFunction
\end{algorithmic}
\caption{\label{algo-searchMemo}Algorithme de recherche d'une valeur optimale mémoisé}
\end{algorithm}

\begin{exo}Donner une valuation numérique aux arcs du \ac{dag} suivant et  simuler l'exécution de l'algorithme \ref{algo-searchMemo} sur papier.
\begin{center}
\begin{tikzpicture}[xscale=2,yscale=2]
\node[shape=circle,draw=black,double=red] (S) at (0,0) {S};
\node[shape=circle,draw=black,double=red] (E) at (4,0) {E};
\node[shape=circle,draw=black] (1) at (1,1) {A};
\node[shape=circle,draw=black] (2) at (3,1) {C};
\node[shape=circle,draw=black] (3) at (2,0) {B};
\draw [->,opacity=0.5](S) -- (1) node[midway,fill=white]{$s(S,A)$};
\draw [->,opacity=0.5](S) -- (3) node[midway,fill=white]{$s(S,B)$};
\draw [->,opacity=0.5](1) -- (3) node[midway,fill=white]{$s(A,B)$};
\draw [->,opacity=0.5](1) -- (2) node[midway,fill=white]{$s(A,C)$};
\draw [->,opacity=0.5](3) -- (2) node[midway,fill=white]{$s(B,C)$};
\draw [->,opacity=0.5](2) -- (E) node[midway,fill=white]{$s(C,E)$};
\draw [->,opacity=0.5](3) -- (E) node[midway,fill=white]{$s(B,E)$};
\end{tikzpicture}
\end{center}
\end{exo}
\begin{exo}
Reformuler l'algorithme \ref{algo-searchMemo} de telle sorte que le chemin optimal 
soit celui de poids minimum.  Simuler son exécution sur papier.
\end{exo}
\begin{exo}
Reformuler l'algorithme \ref{algo-searchMemo} en utilisant la notation en opérations abstraites $\oplus$ et $\otimes$
\end{exo}
\begin{exo}
Reformuler l'algorithme \ref{algo-searchMemo} en supprimant la conditionnelle qui réalise la mémoisation.  Tenter de le simuler sur papier.
\end{exo}

\section{Algorithme de Viterbi}
L'algorithme mémoisé présenté dans la section précédente peut se reformuler par une version souvent plus pratique à l'usage. C'est l'\kw{algorithme de Viterbi}.

\begin{definition}[Ordre topologique] Un ordre topologique sur un \ac{dag} $G=(V,E)$ est tout ordre total sur les noeuds $V$ de ce \ac{dag} tel que pour tout couple de noeuds $(x,y) \in E$,  $x \prec y$. Il existe en général plusieurs ordres topologiques valides pour un \ac{dag} donné.
\end{definition}

L'algorithme de Viterbi est un algorithme de recherche du chemin de
poids maximal dans un \ac{dag} (Figure \ref{algo-viterbi-general}). 
 En supposant un noeud source $s$ unique dont le poids $\delta(s)$ est
 initialisé à 1, l'algorithme parcourt le \ac{dag} en suivant l'ordre
 topologique. Chaque noeud est à son tour valué par le poids
 $\delta(s)$ du chemin maximal qui mène de la source jusqu'à ce
 noeud. Toute l'idée de l'algorithme consiste à mémoriser les poids
 $\delta(s)$ au fur et à mesure qu'ils sont calculés pour les
 réutiliser lors de calculs ultérieurs.

\begin{algorithm}[htbp]
\begin{algorithmic}
\Function{Viterbi}{S,V,s}
\State \Call{TriTopologique}{$S,V,s$}
\State $\delta(s) \gets \bar{1}$
\ForAll {$s \in  S$ (suivant ordre topologique)}
\State $\delta(s) \gets \bar{0}$
\ForAll {$(s',s) \in AE(s)$}
\State  $\delta(s) \gets \Call{$\oplus$}{\delta(s) , \delta(s')  \otimes \psi(s',s) $}
\EndFor
\EndFor
\EndFunction
\end{algorithmic}
\caption{\label{algo-viterbi-general}Algorithme de Viterbi}
\end{algorithm}

On donne en figure \ref{fig-viterbi-general-dag} un exemple de
résultat de l'exécution de l'algorithme sur un cas concret. Chacun des
noeuds du \ac{dag} est annoté (case bleue) par la valeur du $\delta(x)$
qui lui correspond.

\begin{figure}[htbp]
\begin{center}
\begin{tikzpicture}[xscale=2,yscale=3]
\def\x{0.0}
\def\y{0.2}
\node[shape=circle,draw=black,double=red] (S) at (0,0.5) {S};
\node[shape=circle,draw=black,double=red] (E) at (4,0.5) {E};
\node[shape=circle,draw=black] (1) at (1,0) {A};
\node[shape=circle,draw=black] (2) at (1,1) {B};
\node[shape=circle,draw=black] (3) at (2,0) {A};
\node[shape=circle,draw=black] (4) at (2,1) {B};
\node[shape=circle,draw=black] (5) at (3,0) {A};
\node[shape=circle,draw=black] (6) at (3,1) {B};

\draw [->,opacity=0.75](S) -- (1) node[midway,fill=white]{5};
\draw [->,opacity=0.75](S) -- (2) node[midway,fill=white]{2};
\draw [->,opacity=0.75](1) -- (3) node[midway,fill=white]{3};
\draw [->,opacity=0.75](1) -- (4) node[near end,fill=white]{4};
\draw [->,opacity=0.75](2) -- (3) node[near end,fill=white]{7};
\draw [->,opacity=0.75](2) -- (4) node[midway,fill=white]{4};
\draw [->,opacity=0.75](3) -- (5) node[midway,fill=white]{2};
\draw [->,opacity=0.75](3) -- (6) node[near end,fill=white]{3};
\draw [->,opacity=0.75](4) -- (5) node[near end,fill=white]{2};
\draw [->,opacity=0.75](4) -- (6) node[midway,fill=white]{1};
\draw [->,opacity=0.75](5) -- (E) node[midway,fill=white]{2};
\draw [->,opacity=0.75](6) -- (E) node[midway,fill=white]{3};

%deltas
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (0+\x,0.5+\y){1};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (4+\x,0.5+\y){135};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (1+\x,0+\y){5};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (1+\x,1+\y){2};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (2+\x,0+\y){15};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (2+\x,1+\y){20};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (3+\x,0+\y){40};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (3+\x,1+\y){45};
\end{tikzpicture}
\end{center}
\caption{\label{fig-viterbi-general-dag}\ac{dag} annoté par $\delta(x)$}
\end{figure}


\begin{exo}[Limitation aux \ac{dags}]
L'algorithme de Viterbi ne peut pas être utilisé si le graphe contient
au moins un cycle (le graphe n'est pas un \ac{dag}). Expliquer
pourquoi par un exemple.
\end{exo}
\begin{exo}[Extraction de la séquence de poids maximal]
Donner une extension de l'algorithme donné en figure
\ref{algo-viterbi-general} qui permet de renvoyer comme résultat non
seulement le score du chemin de poids maximal (plus long chemin) mais
aussi la séquence de tags de ce chemin.
\end{exo}


\begin{figure}[htbp]
\begin{center}
\begin{tikzpicture}[xscale=1.5,yscale=1.5]
    \node[shape=circle,draw=black] (A1) at (1,1) {D};
    \node[shape=circle,draw=black] (B1) at (1,2) {N};
    \node[shape=circle,draw=black] (C1) at (1,3) {A};
    \node[shape=circle,draw=black] (D1) at (1,4) {P};
    \node[shape=circle,draw=black] (E1) at (1,5) {V};
     \node[shape=circle,draw=black] (A2) at (2,1) {D};
    \node[shape=circle,draw=black] (B2) at (2,2) {N};
    \node[shape=circle,draw=black] (C2) at (2,3) {A};
    \node[shape=circle,draw=black] (D2) at (2,4) {P};
    \node[shape=circle,draw=black] (E2) at (2,5) {V};
     \node[shape=circle,draw=black] (A3) at (3,1) {D};
    \node[shape=circle,draw=black] (B3) at (3,2) {N};
    \node[shape=circle,draw=black] (C3) at (3,3) {A};
    \node[shape=circle,draw=black] (D3) at (3,4) {P};
    \node[shape=circle,draw=black] (E3) at (3,5) {V};
     \node[shape=circle,draw=black] (A4) at (4,1) {D};
    \node[shape=circle,draw=black] (B4) at (4,2) {N};
    \node[shape=circle,draw=black] (C4) at (4,3) {A};
    \node[shape=circle,draw=black] (D4) at (4,4) {P};
    \node[shape=circle,draw=black] (E4) at (4,5) {V};
     \node[shape=circle,draw=black] (A5) at (5,1) {D};
    \node[shape=circle,draw=black] (B5) at (5,2) {N};
    \node[shape=circle,draw=black] (C5) at (5,3) {A};
    \node[shape=circle,draw=black] (D5) at (5,4) {P};
    \node[shape=circle,draw=black] (E5) at (5,5) {V};
    \node[draw=white,text depth=0.25ex,text height=1cm] (W1) at (1,0) {La} ;
    \node[draw=white,text depth=0.25ex,text height=1cm] (W2) at (2,0) {belle} ;
    \node[draw=white,text depth=0.25ex,text height=1cm] (W3) at (3,0) {porte} ;
    \node[draw=white,text depth=0.25ex,text height=1cm] (W4) at (4,0) {le} ;
    \node[draw=white,text depth=0.25ex,text height=1cm] (W5) at (5,0) {cache} ;
    \node[shape=circle,draw=black,double=red] (S) at (0,3) {S};
 \node[shape=circle,draw=black,double=red] (E) at (6,3) {E};

 \draw [->,ultra thick,opacity=0.5] (S) -- (A1);
 \draw [->,opacity=0.5] (S) -- (B1);
 \draw [->,opacity=0.5] (S) -- (C1);
 \draw [->,opacity=0.5] (S) -- (D1);
 \draw [->,opacity=0.5] (S) -- (E1);
 
 \draw [->,opacity=0.5] (A1) -- (A2);
 \draw [->,opacity=0.5] (A1) -- (B2);
 \draw [->,ultra thick,opacity=0.5] (A1) -- (C2);
 \draw [->,opacity=0.5] (A1) -- (D2);
 \draw [->,opacity=0.5] (A1) -- (E2);

\draw [->,opacity=0.5] (B1) -- (A2);
 \draw [->,opacity=0.5] (B1) -- (B2);
 \draw [->,opacity=0.5] (B1) -- (C2);
 \draw [->,opacity=0.5] (B1) -- (D2);
 \draw [->,opacity=0.5] (B1) -- (E2);

\draw [->,opacity=0.5]  (C1) -- (A2);
 \draw [->,opacity=0.5] (C1) -- (B2);
 \draw [->,opacity=0.5] (C1) -- (C2);
 \draw [->,opacity=0.5] (C1) -- (D2);
 \draw [->,opacity=0.5] (C1) -- (E2);

\draw [->,opacity=0.5]  (D1) -- (A2);
 \draw [->,opacity=0.5] (D1) -- (B2);
 \draw [->,opacity=0.5] (D1) -- (C2);
 \draw [->,opacity=0.5] (D1) -- (D2);
 \draw [->,opacity=0.5] (D1) -- (E2);
 
 \draw [->,opacity=0.5]  (E1) -- (A2);
 \draw [->,opacity=0.5] (E1) -- (B2);
 \draw [->,opacity=0.5] (E1) -- (C2);
 \draw [->,opacity=0.5] (E1) -- (D2);
 \draw [->,opacity=0.5] (E1) -- (E2);
 
 \draw [->,opacity=0.5] (A2) -- (A3);
 \draw [->,opacity=0.5] (A2) -- (B3);
 \draw [->,opacity=0.5] (A2) -- (C3);
 \draw [->,opacity=0.5] (A2) -- (D3);
 \draw [->,opacity=0.5] (A2) -- (E3);

\draw [->,opacity=0.5] (B2) -- (A3);
 \draw [->,opacity=0.5] (B2) -- (B3);
 \draw [->,opacity=0.5] (B2) -- (C3);
 \draw [->,opacity=0.5] (B2) -- (D3);
 \draw [->,opacity=0.5] (B2) -- (E3);

\draw [->,opacity=0.5]  (C2) -- (A3);
 \draw [->,ultra thick,opacity=0.5] (C2) -- (B3);
 \draw [->,opacity=0.5] (C2) -- (C3);
 \draw [->,opacity=0.5] (C2) -- (D3);
 \draw [->,opacity=0.5] (C2) -- (E3);

\draw [->,opacity=0.5]  (D2) -- (A3);
 \draw [->,opacity=0.5] (D2) -- (B3);
 \draw [->,opacity=0.5] (D2) -- (C3);
 \draw [->,opacity=0.5] (D2) -- (D3);
 \draw [->,opacity=0.5] (D2) -- (E3);
 
 \draw [->,opacity=0.5]  (E2) -- (A3);
 \draw [->,opacity=0.5] (E2) -- (B3);
 \draw [->,opacity=0.5] (E2) -- (C3);
 \draw [->,opacity=0.5] (E2) -- (D3);
 \draw [->,opacity=0.5] (E2) -- (E3);

 \draw [->,opacity=0.5] (A3) -- (A4);
 \draw [->,opacity=0.5] (A3) -- (B4);
 \draw [->,opacity=0.5] (A3) -- (C4);
 \draw [->,opacity=0.5] (A3) -- (D4);
 \draw [->,opacity=0.5] (A3) -- (E4);

\draw [->,opacity=0.5] (B3) -- (A4);
 \draw [->,opacity=0.5] (B3) -- (B4);
 \draw [->,opacity=0.5] (B3) -- (C4);
 \draw [->,ultra thick,opacity=0.5] (B3) -- (D4);
 \draw [->,opacity=0.5] (B3) -- (E4);

\draw [->,opacity=0.5]  (C3) -- (A4);
 \draw [->,opacity=0.5] (C3) -- (B4);
 \draw [->,opacity=0.5] (C3) -- (C4);
 \draw [->,opacity=0.5] (C3) -- (D4);
 \draw [->,opacity=0.5] (C3) -- (E4);

\draw [->,opacity=0.5]  (D3) -- (A4);
 \draw [->,opacity=0.5] (D3) -- (B4);
 \draw [->,opacity=0.5] (D3) -- (C4);
 \draw [->,opacity=0.5] (D3) -- (D4);
 \draw [->,opacity=0.5] (D3) -- (E4);
 
 \draw [->,opacity=0.5] (E3) -- (A4);
 \draw [->,opacity=0.5] (E3) -- (B4);
 \draw [->,opacity=0.5] (E3) -- (C4);
 \draw [->,opacity=0.5] (E3) -- (D4);
 \draw [->,opacity=0.5] (E3) -- (E4);

 \draw [->,opacity=0.5] (A4) -- (A5);
 \draw [->,opacity=0.5] (A4) -- (B5);
 \draw [->,opacity=0.5] (A4) -- (C5);
 \draw [->,opacity=0.5] (A4) -- (D5);
 \draw [->,opacity=0.5] (A4) -- (E5);

\draw [->,opacity=0.5] (B4) -- (A5);
 \draw [->,opacity=0.5] (B4) -- (B5);
 \draw [->,opacity=0.5] (B4) -- (C5);
 \draw [->,opacity=0.5] (B4) -- (D5);
 \draw [->,opacity=0.5] (B4) -- (E5);

\draw [->,opacity=0.5]  (C4) -- (A5);
 \draw [->,opacity=0.5] (C4) -- (B5);
 \draw [->,opacity=0.5] (C4) -- (C5);
 \draw [->,opacity=0.5] (C4) -- (D5);
 \draw [->,opacity=0.5] (C4) -- (E5);

\draw [->,opacity=0.5]  (D4) -- (A5);
 \draw [->,opacity=0.5] (D4) -- (B5);
 \draw [->,opacity=0.5] (D4) -- (C5);
 \draw [->,opacity=0.5] (D4) -- (D5);
 \draw [->,ultra thick,opacity=0.5] (D4) -- (E5);
 
 \draw [->,opacity=0.5] (E4) -- (A5);
 \draw [->,opacity=0.5] (E4) -- (B5);
 \draw [->,opacity=0.5] (E4) -- (C5);
 \draw [->,opacity=0.5] (E4) -- (D5);
 \draw [->,opacity=0.5] (E4) -- (E5);

 \draw [->,opacity=0.5] (A5) -- (E);
 \draw [->,opacity=0.5] (B5) -- (E);
 \draw [->,opacity=0.5] (C5) -- (E);
 \draw [->,opacity=0.5] (D5) -- (E);
 \draw [->,ultra thick,opacity=0.5] (E5) -- (E);

\end{tikzpicture}
\end{center}
\caption{\label{fig-pos-dag}Graphe acyclique orienté pour énumérer les solutions de manière compacte}
\end{figure}


\paragraph{Viterbi pour l'étiquetage morphosyntaxique}
Dans le cas de l'étiquetage morphosyntaxique en \ac{tal}, le \ac{dag}
de programmation dynamique est conventionnellement construit comme
illustré en figure \ref{fig-pos-dag}. Pour chaque occurrence de mot
$w_i$ dans la phrase, on construit un noeud correspondant à chacun des tags possibles.
Chacun de ces noeuds est connecté par un arc à l'ensemble des noeuds
de la position suivante $w_{i+1}$ dans la phrase. 



En utilisant cette représentation, évaluer successivement les noeuds
de gauche à droite,  c'est-à-dire en valuant l'ensemble des mots de
$w_i$  avant ceux de $w_{i+1}$ revient à valuer le graphe suivant un
ordre topologique valide.

Dans ce contexte spécifique, il est classique de stocker les quantités
$\delta(s)$ dans une matrice $\Delta$ à $i$ colonnes et $j$ lignes.
Chaque ligne correspond à un pos tag parmi un ensemble de $K$ tags et chaque colonne à une position
dans une phrase de $N$ mots. Ainsi $\delta(i,j)$ correspond au score du noeud en
position $i$ taggué par le tag $j$. L'algorithme prend alors la forme
donnée en Algorithme \ref{algo-viterbi-table} où on choisit de 
ne pas expliciter l'état cible noté $E$ dans les exemples précédents.

Cette dernière version permet également de mettre en évidence que la complexité
de l'algorithme est en ${\cal O}(NK^2)$.  
Autrement dit la méthode de programmation dynamique permet de
donner une solution en temps polynomial à un problème dont la
résolution naïve est en temps exponentiel.

\begin{algorithm}[htbp]
\begin{algorithmic}
\Function{Viterbi}{$N$,$K$,$s$}
\For{$j \leq 0 < K $}\Comment{Initialisation}
\State $\delta(0,j) \gets \psi(s ,[0,j]$) 
\EndFor
\For {$0 < i <  N$}\Comment{Recurrence}
    \For{$j \leq 0 < K $}
        \State $\delta(i,j) \gets \bar{0}$
        \For {$0\leq  k < K$}
        \State  $\delta(i,j) \gets \Call{$\oplus$}{\delta(i,j) ,
          \delta(i-1,k)  \otimes \psi([i-1,k] ,[i,j]) $}
\EndFor
\EndFor
\EndFor
\EndFunction
\end{algorithmic}
\caption{\label{algo-viterbi-table}Algorithme de Viterbi (version tabulaire)}
\end{algorithm}

Ce type de formulation est fréquemment utilisée dans les
implémentations. Signalons que dans un contexte d'implémentation il est d'usage de
ne pas représenter explicitement les arcs du \ac{dag} mais plutôt de
construire directement la matrice de scores $\Delta$.

\begin{exo}[Historique de dérivation]
Augmenter l'algorithme \ref{algo-viterbi-table} pour qu'il renvoie
également la séquence de tags de score maximal.
\end{exo}

\section{Abstractions algébriques}
\label{sec-semi-ring}

Les algorithmes que nous présentons ici sont destinés à être utilisés
en combinaison avec une méthode d'apprentissage.
C'est cette dernière
qui donne une méthode pour valuer la fonction $\psi$ et pour estimer
les éventuels paramètres qui lui sont associés.

L'algorithme de Viterbi est un algorithme qui ne fait rien
d'autre que de calculer un {\sl max} ou un {\sl argmax} pour un
très grand ensemble de séquences.

Or chaque méthode d'apprentissage manipule des poids qui se combinent
différemment. Par exemple pour calculer le poids d'une séquence avec
un \ac{hmm} il faut réaliser une multiplication alors qu'avec un
perceptron il faut réaliser une addition. L'algorithme de Viterbi peut
être réutilisé pour chacun de ces paradigmes mais avec les ajustements
nécessaires au système de pondération du paradigme en question.

Nous introduisons ici la notion de demi-anneau
car elle permet de spécifier l'interface entre les
algorithmes présentés ici et des
modèles d'apprentissage variés. 
Plus spécifiquement cette notion aide à caractériser
les conditions d'utilisation d'un algorithme de recherche (notamment
celui de Dijkstra) pour un
un modèle d'apprentissage. En second lieu elle donne des points de
repères sur les paramètres à considérer pour adapter les algorithmes
aux problèmes d'apprentissage traités. Et finalement cela permet de
dériver de nouvelles utilisations pour un algorithme donné.

Un \kw{demi-anneau} est une structure algébrique abstraite qui
permet de généraliser le calcul avec des nombres naturels (ensemble
$\mathbb{N}$)\footnote{Le calcul avec des entiers (ou des réels) se
  généralise par une structure d'\kw{anneau}. C'est-à-dire qu'on a
  nécessairement des
additifs inverses.}.
Le calcul suppose deux opérations~: l'addition qui est commutative et
qui a un élément neutre noté $\bar{0}$, la multiplication qui peut
être commutative et qui a un élément neutre noté
$\bar{1}$. De plus la multiplication distribue sur l'addition et
$\bar{0}$ est absorbant pour la multiplication.
Contrairement aux \kw{anneaux}, les demi-anneaux n'ont pas
nécessairement un additif inverse tel que $a \oplus -a = \bar{0}$.

Un demi anneau est un quintuple $(E,\oplus,\otimes,\bar{0},\bar{1})$
où $E$ est un ensemble, 
$\oplus$ l'opération d'addition, $\otimes$ l'opération de multiplication, $\bar{0}$ le neutre pour l'addition et
$\bar{1}$ le neutre pour la multiplication.  

L'intérêt d'utiliser cette généralisation dans la spécification des
algorithmes est de donner une formulation unique d'un algorithme qu'il
ne reste plus qu'à instancier avec le demi-anneau correspondant au
problème d'apprentissage à traiter. On donne en figure \ref{fig-semirings} quelques exemples de
demi-anneaux qui sont utilisés dans ce cours.

\begin{figure}[htbp]
\begin{center}
\scalebox{0.85}{
\begin{tabular}{llccccl}\toprule
Nom   &Ensemble&$\oplus$&$\otimes$&$\bar{0}$&$\bar{1}$&Usage possible\\\midrule
Viterbi& $[0,1]$    & max&$\times$&0&1&meilleure séquence
(\ac{hmm})\\
Viterbi-\ac{crf}& $\mathbb{R}^+$  & max&$\times$&0&1&meilleure
séquence (\ac{crf})\\
Viterbi-réel& $\mathbb{R}\cup\{-\infty\} $ &max&+&$-\infty$&0&meilleure
séquence (perceptron)\\
Tropical& $\mathbb{R}^+\cup \{-\infty\}$&min&+&$-\infty$&0&plus court chemin ($-log(p)$)\\
Avant    &$[0,1]$ &+&$\times$&0&1&Algorithme avant (\ac{hmm})\\
Avant-\ac{crf} &$\mathbb{R}^+$ &+&$\times$&0&1&Algorithme avant (\ac{crf})\\
Comptage&$\mathbb{N}$ &+&$\times$&0&1&Compte le nombre de séquences\\
\bottomrule
\end{tabular}}
\end{center}
\caption{\label{fig-semirings}Quelques demi-anneaux utilisés dans ce cours}
\end{figure}

On termine par donner quelques définitions et propriétés qui seront
utiles notamment dans les sections suivantes.  Un demi-anneau
$(E,\oplus,\otimes,\bar{0},\bar{1})$ 
est \kw{idempotent} si $e \oplus e = e \qquad (\forall e \in E)$.
Si le demi-anneau est idempotent, on peut alors définir la relation
d'ordre partiel $\leq$ comme suit~:
\begin{displaymath}
a \leq b \,\Leftrightarrow\,  (a\oplus b) = a
\end{displaymath}
appelée ordre naturel de $E$. On dit qu'un demi-anneau a la propriété
de \kw{supériorité} si pour tout couple $a,b \in E$:
\begin{displaymath}
a\leq a \otimes b, \qquad b \leq a\otimes b
\end{displaymath}
Ce qui revient à dire que combiner par multiplication deux quantités
$a,b$ renvoie comme résultat une valeur plus grande. Cette propriété est
requise pour utiliser l'algorithme de Dijkstra ou ses dérivés (y
compris l'algorithme de Knuth) dans un contexte de prédiction structurée.




\begin{exo}[Algorithme somme produit]
Instancier l'algorithme de Viterbi (Algorithme
\ref{algo-viterbi-general}) en utilisant le demi anneau 
appelé Avant-\ac{crf} (Figure \ref{fig-semirings}). Simuler ce nouvel
algorithme à l'aide de l'exemple  de \ac{dag} donné en figure
\ref{fig-viterbi-general-dag}. Donner en français une explication de
ce que cet algorithme calcule. 
\end{exo}


\section{Algorithme de Dijkstra et recherche A$\star$}

Dans certains cas, il est possible de reformuler le problème de recherche de la séquence
de poids maximal dans un \ac{dag} comme un problème du plus court
chemin dans un graphe de telle sorte que le problème se résoud avec
l'algorithme de Dijkstra.
 
Intuitivement l'algorithme de Dijkstra peut s'utiliser dans un
contexte de tagging lorsque les scores associés aux arcs
s'interprètent comme des mesures dites de surprise (\cite{hale}) que l'on obtient à partir
de probabilités $(\text{surprise} =  -\log_2(p))$.


\begin{algorithm}[htbp]
\begin{algorithmic}
\Function{Dijsktra}{$S$,$E$,source,but}
\State $ \delta(s) \gets +\infty$\qquad$(\forall s \in S)$ 
\State $ \delta(\text{source}) \gets \bar{1}$ 
\State $Q \gets s$
\State $V \gets \emptyset$
\While {$Q \not = \emptyset$}
    \State $s \gets$ \Call{Extraire-Min}{$Q$} 
    \State $V \gets V \cup \{s\}$
    \If{$s =$ but}
        \State\Return $\delta(s)$
    \EndIf
    \ForAll{$(s,s') \in AS(s)$}
    \If{$s'\not \in V$}
        \State localscore $\gets \delta(s) \otimes \psi(s,s')$
        \If{localscore $<\delta(s')$}
              \State $\delta(s') \gets$ localscore
              \State \Call{ReordonnerClé}{Q,s'}
        \EndIf
       \EndIf
    \EndFor
\EndWhile
\EndFunction
\end{algorithmic}
\caption{\label{algo-dijkstra-general}Algorithme de Dijkstra}
\end{algorithm}


Commençons par rappeler le fonctionnement de l'algorithme de Dijkstra
dans le cas classique. On suppose un graphe dont les arcs sont
pondérés par des distances entre des stations de métro. Le problème est de trouver le
plus court chemin entre deux stations, la première est appelée la
source, la seconde la destination.

L'algorithme suppose un graphe $G= \langle S,E \rangle$ une file de priorité $Q$. Une file de priorité
est une structure de donnée qui maintient ses arguments triés. On peut
ainsi lui ajouter des éléments pondérés et extraire l'élément de
poids minimal\footnote{On suppose que les poids des éléments
  définissent la relation d'ordre.}.

L'algorithme de Dijkstra, détaillé en Algorithme
\ref{algo-dijkstra-general}, est conceptuellement très simple. 
L'invariant se résume comme suit.
L'algorithme procède en évaluant comment progresser à partir du noeud
$s$ du graphe qui est le plus proche de la source.
Aucun chemin alternatif plus court ne peut mener à $s$ sinon ce serait
un noeud sur ce chemin alternatif qui serait
sélectionné à la place de $s$. L'algorithme termine quand le noeud $s$
est le but à atteindre.

Il faut remarquer que l'algorithme de Dijkstra fonctionne uniquement
si les poids des chemins sont positifs. Dans le cas où certains
chemins ont des poids négatifs, l'algorithme donne un résultat incorrect.

\begin{figure}
\scalebox{0.7}{
\begin{tikzpicture}[xscale=2.5,yscale=2.5]
    \node[shape=ellipse,draw=black] (C) at (-0.5,0.3) {Châtelet};
    \node[shape=ellipse,draw=black] (E) at (-2.5,1) {Etoile};
    \node[shape=ellipse,draw=black] (N) at (3,0) {Nation};
    \node[shape=ellipse,draw=black] (S) at (-1.5,2.5) {Saint-Lazare};
    \node[shape=ellipse,draw=black] (R) at (1,1) {République};
    \node[shape=ellipse,draw=black] (B) at (0.75,-0.25) {Bastille};
    \node[shape=ellipse,draw=black] (M) at (-1.4,-1.5) {Montparnasse};
    \node[shape=ellipse,draw=black] (O) at (-1,1) {Opéra};
    \node[shape=ellipse,draw=black] (I) at (0.75,-2) {Pl. Italie};


    \node[shape=rectangle,fill=white] (X) at (-0.55,1.5) {3};
    \node[shape=rectangle,fill=white] (Y) at (-0.25,2.4) {22};

    \draw [-,opacity=1] (C) -- (O) node[midway,fill=white]{3};
    \draw [-,opacity=1] (C) -- (B) node[midway,fill=white]{3};
    \draw [-,opacity=1] (C) -- (R) node[near end,fill=white]{4};
    \draw [-,opacity=1] (C) -- (E) node[midway,fill=white]{7};
    \draw [-,opacity=1] (C) -- (M) node[midway,fill=white]{7};
    \draw [-,opacity=1] (C) -- (I) node[midway,fill=white]{7};
    \draw [-,opacity=1] (C) -- (I) node[midway,fill=white]{6};
    \draw [-,opacity=1] (C) to [out=30,in=-70] (S);
    \draw [-,opacity=1] (E) -- (M) node[midway,fill=white]{11};
    \draw [-,opacity=1] (M) -- (I) node[midway,fill=white]{7};
    \draw [-,opacity=1] (B) -- (I) node[midway,fill=white]{5};
    \draw [-,opacity=1] (B) -- (R) node[midway,fill=white]{4};
    \draw [-,opacity=1] (N) -- (I) node[midway,fill=white]{9};
    \draw [-,opacity=1] (N) -- (B) node[midway,fill=white]{3};
    \draw [-,opacity=1] (N) -- (R) node[midway,fill=white]{6};
    \draw [-,opacity=1] (O) -- (R) node[near end,fill=white]{5};
    \draw [-,opacity=1] (O) -- (E) node[midway,fill=white]{3};
    \draw [-,opacity=1] (S) -- (M) node[near end,fill=white]{9};
    \draw [-,opacity=1] (S) -- (O) node[midway,fill=white]{2};
    \draw [-,opacity=1] (S) -- (R) node[midway,fill=white]{9};
    \draw [-,opacity=1] (E) to [out=70,in=90] (N);
\end{tikzpicture}
}
\caption{\label{fig-ratp}Plan simplifié du métro parisien}
\end{figure}

\begin{exo}[De \'Etoile à Nation]
Simuler l'algorithme de Dijkstra pour calculer le plus court chemin
entre \'Etoile et Nation sur le plan du métro parisien donné en Figure \ref{fig-ratp}.
\end{exo}
\begin{exo}[De place d'Italie à Saint-Lazare]
Simuler l'algorithme de Dijkstra pour calculer le plus court chemin
entre Place d'Italie et Saint-Lazare sur le plan du métro parisien donné en Figure \ref{fig-ratp}.
\end{exo}
\begin{center}
\scalebox{0.7}{
\begin{tabular}{cl}\toprule
Itération&File de priorité ($Q$)\\\midrule
1& Italie(0)\\
2& Bastille(5) $\prec$ Chatelet(6) $\prec$ Montparnasse(7) $\prec$ Nation(9)\\
3& Chatelet(6) $\prec$ Montparnasse(7) $\prec$ Nation(8) $\prec$ République(9)\\
4& Montparnasse(7) $\prec$ Nation(8) $\prec$ Saint-Lazare(9) $\prec$ Opéra(9) $\prec$ Republique(10) $\prec$ Etoile(13)\\
5 & Nation(8) $\prec$ Saint-Lazare(9) $\prec$ Opéra(9) $\prec$ Republique(10) $\prec$ Etoile(13)\\
6 & {\bf Saint-Lazare(9)} $\prec$ Opéra(9) $\prec$ Republique(10) $\prec$ Etoile(13)\\\bottomrule
\end{tabular}}
\end{center}

\begin{exo}[Historique]
Donner une extension au pseudo-code en figure
\ref{algo-dijkstra-general} pour renvoyer également le plus court
chemin et pas seulement sa valeur.
\end{exo}
\begin{exo}[Invariant de l'algorithme et poids négatifs]
Donner un exemple de graphe comportant au moins un arc de poids
négatif pour lequel une exécution naïve de l'algorithme de Dijkstra
renvoie un résultat incorrect.
\end{exo}
\begin{exo}[Graphe acyclique orienté]
En faisant l'hypothèse que le graphe est un \ac{dag}, proposez une
simplification de l'algorithme \ref{algo-dijkstra-general}
\end{exo}

\paragraph{Application de l'algorithme de Dijkstra en \ac{tal}} 
 Pour les problèmes de \ac{tal} comme le tagging, le problème peut se
 reformuler comme un problème de recherche du plus court chemin
 lorsque le modèle d'apprentissage produit des poids qui s'apparentent
 à des probabilités.  Dans le cadre de ce cours, cet algorithme sera donc approprié pour
être utilisé en combinaison avec des modèles d'apprentissage tels que
\ac{hmm}, \ac{memm} et des modèles neuronaux qui généralisent \ac{memm}.

L'algorithme peut ainsi être réutilisé en représentant le problème par
un graphe identique aux \ac{dags} de programmation dynamique manipulés
par l'algorithme de Viterbi. Contrairement à l'algorithme
de Viterbi, l'algorithme de Dijkstra cherche explicitement un court
chemin, ce qui demande de remplacer la fonction de pondération
probabiliste par une fonction de pondération qui calcule des scores
qui se comportent de manière analogue aux distances entre stations de métro.

Il est d'usage, notamment pour \ac{hmm},
d'utiliser des log-probabilités dans les implémentations pour éviter
les problèmes de manque de précision dans la manipulation de réels
trop proches de 0.  Ici on réutilise cette pratique allègrement~:  si
$p$ est une probabilité de transition, on peut interpréter $-\log(p)$ comme l'effort (ou une longueur de chemin ou encore une surprise) qui permet
d'avancer dans la séquence. Dans ce cas suivre un chemin de très haute
probabilité ($p\approx 1.0$) aura un coût très faible ($-\log(1.0)\approx 0$)
alors que suivre un chemin de très basse probabilité ($p\approx 0.0$)
aura un coût énorme ($-\log(0.0) \approx +\infty$). 
Autrement dit, on suppose que fonction de score $\psi(s_i,s_{i+1}) =
-\log(p)$ où $p$ est une probabilité de transition.
Dans ce contexte, utiliser l'algorithme de Dijkstra revient à chercher
le chemin pour lequel l'effort (ou la surprise) global est le plus
faible\footnote{On verra en section \ref{sec-semi-ring} que ces
  intuitions se formalisent explicitement en termes algébriques. 
L'algorithme de Dijkstra est utilisable lorsque le demi-anneau utilisé pour combiner les
  scores possède une propriété dite de supériorité. Celle-ci
  généralise l'idée que lorsque deux chemins sont combinés la distance
  augmente. Le demi-anneau décrit informellement ici est en fait le demi-anneau tropical.
}.

On peut illustrer cela par un exemple. Considérons les séquence de tags 
$t_1,t_2,t_3,t_4$ et $t_1,t_2,t_3,t_5$. Supposons que $P(t_1) = 0.2, P(t_2|t_1) = 0.8,
P(t_3|t_2) = 0.1,P(t_4|t_3) = 0.5, P(t_5|t_3) = 0.2$. En termes de surprise cumulée, 
on a que~:
\begin{displaymath}
\sigma(t_1,t_2,t_3,t_4) = \sum_{i} \psi(t_{i}, t_{i-1}) = 1.61 + 0.22 + 2.30 + 0.69 
\end{displaymath}
\begin{displaymath}
\sigma(t_1,t_2,t_3,t_5) = \sum_{i} \psi(t_{i} , t_{i-1})  = 1.61 + 0.22 + 2.30 + 1.61 
\end{displaymath}
On voit que la surprise cumulée augmente lors de chaque transition.
et que la séquence de plus haute probabilité aura la plus petite
surprise cumulée. 

On peut démontrer que dans le pire des cas, l'algorithme de Dijkstra a
une complexité un peu plus élevée que l'algorithme de Viterbi. 
La complexité additionnelle est liée à l'usage de la file de priorité
$Q$. 
Par
contre l'algorithme de Viterbi explore en largeur l'ensemble des
noeuds du graphe alors que l'algorithme de Dijkstra est un exemple
d'algorithme d'exploration en profondeur (meilleur d'abord). 
Il est susceptible dans certains cas de
trouver la solution en explorant moins de noeuds. 
C'est ce qui motive l'extension de cet algorithme connue sous le nom d'heuristique \kw{A$\star$}.

\subsection{Algorithme A$\star$}

L'algorithme $A\star$ est un algorithme de recherche du plus court
chemin qui est à voir comme une extension de l'algorithme de Dijkstra.
L'invariant de l'algorithme de
Dijkstra est conservé~: \`a chaque itération c'est le noeud $s$ qui a
le coût $\delta(s)$ le plus faible qui est sélectionné pour la suite de l'exploration.

Par contre l'algorithme $A\star$ change la méthode d'évaluation du
coût. Ce n'est plus uniquement $\delta(s)$ qui représente le coût mais la
combinaison~:
\begin{displaymath}
\phi(s) = \delta(s)+h(s)
\end{displaymath}
Cette fois-ci, le coût $c(s)$ est la somme du coût $\delta(s)$ du
chemin déjà parcouru et d'une heuristique $h(n)$ qui estime le coût du
chemin qui reste à parcourir.  Ainsi l'algorithme de Dijkstra classique est un algorithme $A\star$
pour lequel $h(s) = 0\, (\forall s \in S)$. 


\begin{algorithm}[htbp]
\begin{algorithmic}
\Function{A-star}{$S$,$E$,source,but}
\State $ \phi(s) \gets +\infty$\qquad$(\forall s \in S)$ 
\State $ \phi(\text{source}) \gets \bar{1}$ 
\State $Q \gets \text{source}$
\State $V \gets \emptyset$
\While {$Q \not = \emptyset$}
    \State $s \gets$ \Call{Extraire-Min}{$Q$} 
    \State $V \gets V \cup s$
    \If{$s =$ but}
        \State\Return $\delta(s)$
    \EndIf
    \ForAll{$(s,s') \in AS(s)$}
      \If{$s' \not \in V$}
        \State localscore $\gets \delta(s) \otimes \psi(s,s') \otimes h(s')$        
        \If{localscore $<\phi(s')$}
              \State $\phi(s') \gets$ localscore
              \State $\delta(s') \gets \delta(s) \otimes \psi(s,s')$ 
              \State \Call{ReordonnerClé}{Q,s'}
        \EndIf
        \EndIf
    \EndFor
\EndWhile
\EndFunction
\end{algorithmic}
\caption{\label{algo-astar-general}Algorithme A$\star$}
\end{algorithm}


\paragraph{Conception de l'heuristique} La difficulté lors de la
conception d'un algorithme $A\star$ consiste à définir une heuristique
qui permette d'obtenir une \kw{solution optimale}. 
Un algorithme de recherche de court chemin qui renvoie une solution
optimale est un algorithme qui renvoie effectivement comme résultat la
valeur du plus court chemin entre deux points. C'est ce que garantit
l'algorithme de Dijkstra.

Si l'heuristique $h(s)$ est mal définie l'algorithme $A\star$ n'est
pas garanti de renvoyer la solution optimale. On propose d'illustrer
ce point par l'exemple de la recherche du court chemin entre {\sl Place
d'Italie} et {\sl Saint Lazare} à partir du graphe \ref{fig-ratp}.
en comparant l'effet des heuristiques $h_1(s)$ et $h_2(s)$ suivantes
sur la procédure de recherche~:
\begin{center}
\begin{tabular}{lll}\\\toprule
  $s$ & $h_1(s)$&$h_2(s)$\\\midrule
Châtelet& 1&11\\
Bastille&5&12\\
Opéra & 1&1\\
Montparnasse&4&4\\
Nation & 12&12\\
Etoile & 1&1\\
Autres & 0&0\\\bottomrule
\end{tabular}
\end{center}
\begin{center}
\scalebox{0.65}{
\begin{tabular}{cl}\toprule
Itération&File de priorité ($Q$) pour l'heuristique $h_1$\\\midrule
1& Italie(0)\\
2 & Chatelet(7) $\prec$ Bastille(10)  $\prec$ Montparnasse(11) $\prec$ Nation(21)\\
3 & Bastille(10)  $\prec$ Montparnasse(11) $\prec$ Nation(21)\\
4 & {\bf Saint Lazare(9)} $\prec$ Opéra(10) $\prec$ Republique(10) $\prec$
Montparnasse(11) $\prec$ Etoile(13) $\prec$  Nation(21)\\\bottomrule
\end{tabular}}
\end{center}

\begin{center}
\scalebox{0.8}{
\begin{tabular}{cl}\toprule
Itération&File de priorité ($Q$) pour l'heuristique $h_2$\\\midrule
1& Italie(0)\\
2&Montparnasse(11) $\prec$ Bastille(17) $\prec$ Chatelet(17) $\prec$ Nation(21)\\ 
3&{\bf Saint-Lazare(16)} $\prec$ Etoile(17) $\prec$  Bastille(17) $\prec$ Chatelet(17) $\prec$ Nation(21)\\\bottomrule
\end{tabular}}
\end{center}
On peut constater que l'heuristique $h_1$ renvoie effectivement la solution
optimale en moins d'itérations que l'algorithme de Dijkstra
classique. 
Par contre l'heuristique $h_2$ renvoie une solution non
optimale (en peu d'itérations également).
La cause de la non optimalité de $h_2$ vient essentiellement du fait que l'algorithme
fait -- à tort -- l'hypothèse qu'il est très couteux de rejoindre la
destination en passant par Châtelet~: l'heuristique $h_2$ indique un coût de
11 pour rejoindre la destination alors que le coût réel est de 3.

Une heuristique $h$ est dite \kw{admissible} si pour tout $s\in S$ 
la distance estimée $h(s)$ n'est jamais strictement supérieure à la distance
minimale réelle qu'il reste à parcourir pour atteindre la destination
depuis $s$.

La seconde condition que l'heuristique $h$ doit 
satisfaire pour garantir l'optimalité de l'algorithme est la condition
de \kw{monotonie} (ou de consistance)~:
\begin{displaymath} 
h(s) \leq \psi(s,s') + h(s') \qquad \forall (s,s') \in AS(s) 
\end{displaymath}
Ce qui revient à dire que l'estimation du coût pour arriver à
destination depuis $n$ doit être inférieur au coût pour arriver à
destination à partir de chacun de ses successeurs dans le graphe. C'est une
généralisation de la condition excluant les chemins de poids négatif
pour l'algorithme de Dijkstra. On peut alternativement reformuler
cette condition en incluant le terme $\delta(s)$~:
\begin{displaymath} 
\delta(s) + h(s) \leq \delta(s) + \psi(s,s') + h(s') \qquad \forall (s,s') \in AS(s) 
\end{displaymath}
pour exprimer explicitement que la longueur d'un chemin ne peut pas
raccourcir.
En général satisfaire l'une des deux conditions permet de satisfaire
l'autre. Mais ce n'est pas toujours vrai.

En \ac{tal} la recherche $A\star$ a surtout été utilisée dans des
contextes d'analyse syntaxique automatique (comme extensions de
l'algorithme de Knuth).

En résumé, la conception d'une bonne heuristique $A\star$ est non
triviale. L'heuristique évidente $h(s) = 0$ n'aide pas à réaliser une
meilleure recherche que l'algorithme de Dijkstra. Une heuristique plus informative qui préserve
l'optimalité demande de vérifier des propriétés qui ne sont pas
triviales à satisfaire en pratique. Pour cette raison, on trouve
souvent dans la littérature des heuristiques approximatives qui sacrifient l'optimalité de la solution.


\subsection{Recherche en largeur et en profondeur}
mettre commentaires sur complexité -> depth first plus haute
complexité pire des cas mais espoir d'atteindre la solution plus rapidement.

\section{Les méthodes de recherche approximatives}

Tant l'algorithme de Viterbi que l'algorithme de Dijsktra (et
A$\star$) sont conçus pour donner une solution optimale au problème de
recherche du chemin de poids maximal (resp. minimal).

Bien que ces algorithmes ont une complexité polynomiale --~considérée
comme acceptable~-- ces algorithmes sont potentiellement lents lorsque
les phrases sont longues où lorsque l'espace des états est de taille
considérables. Par exemple, Viterbi a une complexité en ${\cal
  O}(NK^2)$, lorsque la taille du jeu de tags $K$ est importante (ce
qui est notamment le cas pour des modèles dont l'historique est très riche)
les temps de calcul deviennent potentiellement prohibitifs.

Dans ce type de situation, on peut faire le choix d'utiliser des
méthodes de recherche de solutions qui ne garantissent pas
l'optimalité, comme la recherche gloutonne ou la recherche par
faisceau. Il s'agit de méthodes qui n'explorent qu'une petite partie
de l'espace de solutions et qui sont en général très efficaces.

Comme il s'agit de méthodes qui n'explorent qu'une toute petite
partie de l'espace des solutions (séquences de tags possibles)
celle-ci sont généralement utilisées en combinaison avec une fonction
de score très bien informée sur le problème à traiter de telle sorte que la
partie de l'espace explorée a, par hypothèse, de grandes chances de contenir la
solution optimale. 

On présente ici deux méthodes couramment utilisées~:  la recherche
gloutonne et la recherche par faisceau (beam) comme des variantes de
la méthode de recherche dans un arbre de solutions (Algorithme
\ref{algo-searchtree}) pour des systèmes de transitions. 
Mais ces méthodes pourraient également se formuler dans un contexte où l'espace de
recherche est représenté par un graphe.

\subsection{Recherche gloutonne}

La méthode de recherche gloutonne est le cas dégénéré de la méthode de
recherche du meilleur d'abord. \`A chaque itération, l'algorithme évalue
le score de tous les successeurs d'un état. C'est l'unique successeur
de meilleur score qui est sélectionné pour la suite de la recherche
(Algorithme \ref{algo-greedy-tree}).
\begin{algorithm}[htbp]
\begin{algorithmic}[1]
\Function{GreedySearch}{S,B,$\sigma$}
\If{$B \not = \epsilon$}
\State maxscore $\gets \bar{0}$
\ForAll{$t \in T$}
	\State localscore $\gets \sigma \otimes \psi(S,B,t)$
        \State maxscore $\gets$ \Call{$\oplus$}{maxscore,localscore}
\EndFor
\State\Return \Call{GreedySearch}{$S|t$,$_{\ominus}$B, maxscore}
\Else
  \State\Return $\sigma$
\EndIf
\EndFunction
\end{algorithmic}
\caption{\label{algo-greedy-tree}Algorithme de recherche glouton}
\end{algorithm}
Il est évident que cet algorithme donne des solutions approximatives
et sans garantie d'optimalité. Par contre la complexité de cet
algorithme, en ${\cal O}(n K)$,  est linéaire en temps. Autrement dit,
cet algorithme est très efficace à l'usage.

L'aspect approximatif de cet algorithme peut être contrebalancé
en utilisant des scores locaux  très bien choisis pour guider la recherche vers une solution proche de
l'optimum global. Ce
scénario est très utilisé à l'heure actuelle par les systèmes pondérés
par des réseaux de neurones profonds. Ceux-ci  obtiennent
empiriquement de très
bons résultats.

\begin{exo}
Augmenter l'algorithme \ref{algo-greedy-tree} pour qu'il renvoie
non seulement le score du chemin de poids maximal, mais aussi
la séquence de tags de ce chemin.
\end{exo}
\begin{exo}
Comparer le meilleur chemin renvoyé par l'algorithme glouton avec
celui 
renvoyé par l'algorithme de Viterbi à partir de l'exemple \ref{fig-viterbi-general-dag}.
\end{exo}

\subsection{Recherche par faisceau}

La recherche par faisceau est une extension de la méthode par recherche gloutonne.
La recherche par faisceau est un algorithme qui progresse
essentiellement en largeur dans l'arbre de recherche. \`A chaque itération il avance en
profondeur dans $|\mathcal{B}|$ branches de l'arbre jusqu'à atteindre les
feuilles, et ce sans jamais faire marche arrière.

Les $|\mathcal{B}|$ branches sélectionnées pour continuer l'exploration à l'étape
suivante constituent le faisceau. 
Le choix des branches destinées à continuer l'exploration 
est heuristique. Généralement on choisit les $|\mathcal{B}|$ branches qui ont le
plus haut score. 

\begin{algorithm}[htbp]
\begin{algorithmic}[1]
\Function{BeamSearch}{$\mathcal{B}$}
\State $\mathcal{B}' \gets \emptyset$
\ForAll {$\langle S,B,\sigma\rangle \in \mathcal{B}$}
\If {$B = \epsilon$}
\State \Return $\sigma$
\EndIf
\ForAll{$t \in T$}
	\State localscore $\gets \sigma \otimes \psi(S,B,t)$
        \State $\mathcal{B'} \gets \mathcal{B}' \cup \{\langle
        S|t,_\ominus B,\text{localscore}\rangle\}$
\EndFor
\EndFor
\State $\mathcal{B} \gets$ \Call{$\mathcal{B}$-Select}{$\mathcal{B'}$}
\State \Return \Call{BeamSearch}{$\mathcal{B}$}
\EndFunction
\end{algorithmic}
\caption{\label{algo-beam-tree}Algorithme de recherche en faisceau}
\end{algorithm}
L' algorithme est donné en Algorithme \ref{algo-beam-tree}.
Notons que la fonction \ac{$\mathcal{B}$-Select} est chargée de sélectionner $|\mathcal{B}|$ éléments dans un
ensemble. Il s'agit dans la très grande généralité des cas
 de sélectionner les $|\mathcal{B}|$ éléments de scores les plus élevés (ou plus faibles)
 mais des variantes sont envisageables. Par exemple la recherche par faisceau
 stochastique consiste à sélectionner $|\mathcal{B}|$ éléments aléatoirement
 proportionnellement à leur score. 

L'intérêt de cette méthode est son efficacité~: la complexité reste faible~:
${\cal O}(n K |\mathcal{B}|)$, c'est-à-dire essentiellement linéaire.

On peut penser que le faisceau peut corriger les faiblesses de la méthode
gloutonne mais en pratique on observe souvent que les faisceaux
contiennet des hypothèses très similaires.
Comme la méthode gloutonne, l'algorithme de recherche en faisceau ne
garantit pas de renvoyer une solution optimale. 
En effet, une solution optimale qui a un mauvais score préfixe lors
des premières itérations ne sera plus jamais considérée. 

Il faut bien garder à l'esprit que cette méthode renvoie un
pseudo-résultat maximal, ce qui peut avoir des conséquences non
négligeables dans certains contextes d'utilisation
(comme illustré en chapitre XX)

\begin{exo}
Augmenter l'algorithme \ref{algo-beam-tree} pour qu'il renvoie
non seulement le score du chemin de poids maximal, mais aussi
la séquence de tags de ce chemin.
\end{exo}

\chapter{Rappels de classification non structurée}

= modèles + descente de (sous-) gradient.

\section{Minimum d'une fonction strictement convexe}

%$f(\mathop{(\mathbf{x}_i,y_i)}_{i=1}^N)$


\begin{algorithm}
\begin{algorithmic}
\Function{GradientDescent}{$\alpha$,$f(\mathbf{w})$}
\State $\mathbf{w} \gets \mathbf{0}$
\While{non convergence}
\State $\mathbf{w} \gets \mathbf{w} - \alpha \nabla f(\mathbf{w})$
\EndWhile
\State\Return $\mathbf{w}$
\EndFunction
\end{algorithmic}
\caption{Algorithme de descente de gradient}
\end{algorithm}

Maximum d'une fonction strictement concave.

\section{Régression logistique}
{\bf discuter du virage du biais}

\begin{equation}
 P(y_i|\mathbf{x}_i; \mathbf{w}) =\frac{e^{\mathbf{w}^T \mathbf{x}}}{1+e^{\mathbf{w}^T \mathbf{x}}}
\end{equation}

Objective = max de vraisemblance:
\begin{equation}
f(\mathbf{w}) = \prod_{i=1}^N P(y_i|\mathbf{x}_i; \mathbf{w}) 
\end{equation}

On maximise la log-vraisemblance :
\begin{eqnarray}
\hat{\mathbf{w}} &=& \mathop{\text{argmax}}_{\mathbf{w} \in
  \mathbb{R}^d} \prod_{i=1}^N P(y_i|\mathbf{x}_i; \mathbf{w})\\
&=&\mathop{\text{argmax}}_{\mathbf{w} \in  \mathbb{R}^d} \sum_{i=1}^N
\log P(y_i|\mathbf{x}_i; \mathbf{w})\\
&=&\mathop{\text{argmax}}_{\mathbf{w} \in  \mathbb{R}^d} \sum_{i=1}^N
 [ \mathbf{w}^T \mathbf{x}_i ] - \log [ 1+e^{\mathbf{w}^T
  \mathbf{x}_i} ]
\end{eqnarray}

Dérivée partielle de $w_j$ au point $\mathbf{w}$:
\begin{eqnarray}
\frac{\partial f(\mathbf{w})}{\partial w_j}&=&\frac{\partial \sum_{i=1}^N
 [ \mathbf{w}^T \mathbf{x}_i ] - \log [ 1+e^{\mathbf{w}^T
  \mathbf{x}_i} ]}{\partial w_j}\\
&=&\sum_{i=1}^N x_{ij} - \frac{\partial \log [ 1+e^{\mathbf{w}^T
  \mathbf{x}_i} ] }{\partial w_j}\\
&=&\sum_{i=1}^N x_{ij} - 
\frac{\frac{\partial e^{\mathbf{w}^T  \mathbf{x}_i} }{\partial
    w_j}}{1+ e^{\mathbf{w}^T  \mathbf{x}_i}}\\
&=&\sum_{i=1}^N x_{ij} - 
\frac{e^{\mathbf{w}^T  \mathbf{x}_i} x_{ij}} {1+ e^{\mathbf{w}^T  \mathbf{x}_i}}\\
&=&\sum_{i=1}^N x_{ij} - [ P(y_i | \mathbf{x}_i,\mathbf{w}) \, x_{ij} ]
\end{eqnarray}

On note le gradient $\nabla f(\mathbf{w}) = \frac{\partial f}{\partial w_1} \ldots
\frac{\partial f}{\partial w_d}$.

\paragraph{SGD} Observons que le calcul de $\nabla f(\mathbf{w})$ prend la forme~:
\begin{displaymath}
\nabla f(\mathbf{w}) = \sum_{i=1}^N [ \mathbf{x}_i -
P(y_i|\mathbf{x}_i;\mathbf{w}) \mathbf{x}_i ]
\end{displaymath} 
ou plus généralement en ML (beyond logistic)
\begin{displaymath}
\nabla f(\mathbf{w}) = \sum_{i=1}^N \ell(y_i,\mathbf{x}_i; \mathbf{w})
\end{displaymath} 

L'idée de SGD c'est :
\begin{displaymath}
\nabla f(\mathbf{w}) \approx \ell(y_i,\mathbf{x}_i; \mathbf{w}) \qquad
({i \sim \text{\sc Uniform}(1,N)})
\end{displaymath} 


\paragraph{ASGD} 
Le problème de SGD c'est que si un tirage est mauvais en fin de
procédure, ça peut détruire le gradient.
L'idée de ASGD c'est de retenir la valeur moyenne du gradient.

\begin{algorithm}
\begin{algorithmic}
\Function{BatchGradientDescent}{$\alpha,\mathop{(\mathbf{x}_i,y_i)}_{i=1}^N}$
\State $\mathbf{w} \gets \mathbf{0}$
\While{non convergence}
\State $\mathbf{w} \gets \mathbf{w} - \alpha \sum_{i=1}^N \ell (y_i,\mathbf{x}_i;\mathbf{w})$
\EndWhile
\State\Return $\mathbf{w}$
\EndFunction
\end{algorithmic}
\caption{Algorithme de descente de gradient (batch)}
\end{algorithm}


\begin{algorithm}
\begin{algorithmic}
\Function{StochasticGradientDescent}{$\alpha,\mathop{(\mathbf{x}_i,y_i)}_{i=1}^N}$
\State $\mathbf{w} \gets \mathbf{0}$
\While{non convergence}
\State $i \sim$ \Call{Uniform}{1,N}
\State $\mathbf{w} \gets \mathbf{w} - \alpha\, \ell (y_i,\mathbf{x}_i;\mathbf{w})$
\EndWhile
\State\Return $\mathbf{w}$
\EndFunction
\end{algorithmic}
\caption{Algorithme de descente de gradient (SGD)}
\end{algorithm}

\begin{algorithm}
\begin{algorithmic}
\Function{AveragedStochasticGradientDescent}{$\alpha,\mathop{(\mathbf{x}_i,y_i)}_{i=1}^N}$
\State $\mathbf{w} \gets \mathbf{0}$
\State $\bar{\mathbf{w}} \gets \mathbf{0}$
\State $C \gets 0$
\While{non convergence}
\State $i \sim$ \Call{Uniform}{1,N}
\State $\mathbf{w} \gets \mathbf{w} - \alpha\, \ell (y_i,\mathbf{x}_i;\mathbf{w})$
\State $\bar{\mathbf{w}} \gets \bar{\mathbf{w}} + \mathbf{w}$
\State $C \gets C+1$
\EndWhile
\State\Return $\bar{\mathbf{w}}/C$
\EndFunction
\end{algorithmic}
\caption{Algorithme de descente de gradient moyennée (ASGD)}
\end{algorithm}

\section{Régression logistique multinomiale}
{\bf Discuter le codage des features et recommencer}

Modèle : 
\begin{equation}
P(y|\mathbf{x};\mathbf{w}) =  \frac{\text{exp}(\mathbf{w}^T
    \boldsymbol\Phi(\mathbf{x},y)) }{\sum_{y'\in Y} \text{exp}(\mathbf{w}^T
    \boldsymbol\Phi(\mathbf{x},y'))}
\end{equation}

Objective (Max vraisemblance)

\begin{equation}
f(\mathbf{w}) =  \prod_{i=1}^N P(y_i|\mathbf{x}_i;\mathbf{w})
\end{equation}

Dérivée partielle : 

\begin{equation}
\frac{\partial f(\mathbf{w})}{\partial w_j} =  \sum_{i=1}^N \left[\phi_j(\mathbf{x}_{i},y) -
\sum_{y'\in Y} P(y'|\mathbf{x}_i,\mathbf{W}) \phi_j(\mathbf{x}_i,y') \right]
\end{equation}

\begin{displaymath}
\ell(y_i,\mathbf{x}_i,\mathbf{w}) = \boldsymbol\Phi(\mathbf{x}_{i},y)
-  \sum_{y'\in Y} P(y'|\mathbf{x}_i;\mathbf{w}) \boldsymbol\Phi(\mathbf{x}_i,y') 
\end{displaymath}


\section{Perceptron multiclasse}
    
Modèle : 
\begin{equation}
\text{score}(y,\mathbf{x};\mathbf{w}) =  \mathbf{w}^T \,
    \boldsymbol\Phi(\mathbf{x},y)
\end{equation}

Objective (miniser l'erreur): 

\begin{equation}
f(\mathbf{w}) = \sum_{i=1}^N \mathbf{1}[ y_i \not = \mathop{\text{argmax}}_{y' \in Y} \mathbf{w}^T \,
    \boldsymbol\Phi(\mathbf{x}_i,y') ]
\end{equation}

Sous-dérivée partielle : 

soit:
\begin{displaymath}
\hat{y}_i = \mathop{\text{argmax}}_{y' \in
  Y} \mathbf{w}^T \,
   \boldsymbol\Phi(\mathbf{x}_i,y') 
\end{displaymath}
alors:
\begin{equation}
\frac{\partial f(\mathbf{w})}{\partial w_j} =  
\sum_{i=1}^N \left\{
\begin{array}{ll}
\phi_j(\mathbf{x}_{i},y_i) - \phi_j(\mathbf{x}_{i},\hat{y}_i) &\text{si } y_i
\not = \hat{y}_i\\
0&\text{sinon}
\end{array}\right.
\end{equation}


\begin{displaymath}
\ell(y_i,\mathbf{x}_i,\mathbf{w}) = 
\left\{
\begin{array}{ll}
\boldsymbol\Phi(\mathbf{x}_{i},y_i)
- \boldsymbol\Phi(\mathbf{x}_i,\hat{y}_i)&\text{si } y_i \not = \hat{y}_i \\
 \mathbf{0}& \text{sinon}
\end{array}\right.
\end{displaymath}



\section{Large marge multiclasse}
hinge loss
montrer que le gradient est celui du perceptron 
perceptron = large marge avec marge nulle en SGD


\section{Réseau de neurones}
    word vectors
    SGD


\chapter{Perceptron structuré}

Le modèle du perceptron structuré est initialement dû à \cite{collins-2002}.

\section{Généralisation du modèle du perceptron}

Le perceptron structuré est un modèle qui généralise le modèle du
perceptron au cas des données structurées. 
Dans ce chapitre, on donne une présentation pour la modélisation de
séquences. On généralisera ce cas à la prédiction d'arbres dans les
chapitres suivants.

Un perceptron multiclasse est un modèle statistique qui prédit le
score $\psi(y)$ d'une donnée $y\in Y$ de manière linéaire~:
\begin{equation}
\psi(y) = \mathbf{w}^T \boldsymbol\Phi(\mathbf{x},y)
\end{equation}
Comme $\mathbf{w} \in \mathbb{R}^d$ et $\boldsymbol\Phi(\mathbf{x},y)
\in \{0,1\}^d$, on a que $\psi(y) \in \mathbb{R}$. 
Ce modèle est habituellement utilisé dans un contexte de prise de
décision, il s'agit de sélectionner parmi un ensemble $Y$ d'hypothèses, 
l'hypothèse $y\in Y$ de score maximal~:
\begin{equation}
\hat{y} =   \mathop{\text{argmax}}_{y\in Y} \mathbf{w}^T \boldsymbol\Phi(\mathbf{x},y)
\end{equation}

Dans le cas où $Y$ est un ensemble de structures, comme un ensemble de
séquences, la taille de cet ensemble croît exponentiellement en
fonction de la longueur de la phrase. 
L'idée d'un modèle de perceptron structuré est de permettre la
décomposition du calcul du score des séquences de telle sorte qu'il
soit possible de partager des sous-calculs entre des sous-séquences communes.
Ainsi une séquence de tags $\mathbf{y} = y_1,y_2\ldots y_m\ldots $
sera évaluée par la fonction de score suivante~:
\begin{equation}
\Psi(\mathbf{y}) = \sum_{i=1}^m \mathbf{w}^T \boldsymbol\Phi(\mathbf{x},y_{i-1},y_i)
\end{equation}
Autrement dit, le score d'une séquence est la somme des scores
attribués à tous les couples de tags qui la composent. Lorsqu'il
s'agit de donner un score à un ensemble de séquences, il est ainsi
possible de représenter le problème dans un \ac{dag} de programmation
dynamique et de réutiliser l'algorithmique décrite dans les chapitres précédents.


\section{Recherche de la meilleure analyse}

\subsection{Fonctions features}


\begin{exo}[Algorithme de Dijkstra ?]
Est-il possible d'adapter l'algorithme de Dijkstra pour prédire la
meilleure séquence de tags avec un modèle de perceptron structuré ?
si oui comment ? si non, justifiez.
\end{exo}

\section{Estimation des paramètres}

On suppose qu’un corpus annoté $C = \mathop{(\mathbf{x}_i,\mathbf{y}_i)}^N_{i=1}$ est un
exemplaire de $N$ phrases. 
Chaque exemple annoté est un couple $(x_i , y_i )$ qui représente une
séquence de mots $x = x_1 \ldots x_m$ et une séquence de tags de
référence $y = y_1 \ldots y_m$ de même longueur.

\begin{algorithm}[htbp]
\begin{algorithmic}[1]
\Function{train-perceptron}{$\mathop{(\mathbf{x}_i,\mathbf{y}_i)}^N_{i=1}$,$E$}
\State $\mathbf{w} \gets \bar{\mathbf{0}}$
\For{$1\leq e \leq E $}
\For{$1\leq i \leq N$}
\State
$\hat{\mathbf{y}} \gets \mathop{\text{argmax}}_{\mathbf{y}\in \mathbf{Y}} \mathbf{w}^T \boldsymbol\Phi(\mathbf{x}_i,\mathbf{y})$
\Comment{Tagging}
\label{algoline-pseudoargmax}
\If{$\hat{\mathbf{y}} \not = \mathbf{y}_i$}
     \State $\mathbf{w} \gets  \mathbf{w} +
     \left[\boldsymbol\Phi(\mathbf{x}_i,\mathbf{y}_i) 
       - \boldsymbol\Phi(\mathbf{x}_i,\hat{\mathbf{y}})  \right]$ 
     \label{algoline-update}
\EndIf
\EndFor
\EndFor
\State \Return $\mathbf{w}$
\EndFunction
\end{algorithmic}
\caption{\label{algo-perceptron-train}Estimation des paramètres d'un
  perceptron}
\end{algorithm}


\begin{algorithm}[htbp]
\begin{algorithmic}[1]
\Function{train-perceptron}{$\mathop{(\mathbf{x}_i,\mathbf{y}_i)}^N_{i=1}$,$E$}
\State $\mathbf{w} \gets \mathbf{0}$
\State $\bar{\mathbf{w}} \gets \mathbf{0}$
\For{$1\leq e \leq E $}
\For{$1\leq i \leq N$}
\State $\hat{\mathbf{y}} \gets \mathop{\text{argmax}}_{\mathbf{y}\in \mathbf{Y}} \mathbf{w}^T \boldsymbol\Phi(\mathbf{x}_i,\mathbf{y})$
\Comment{Tagging}
\If{$\hat{\mathbf{y}} \not = \mathbf{y}_i$}
     \State $\mathbf{w} \gets  \mathbf{w} +
     \left[\boldsymbol\Phi(\mathbf{x}_i,\mathbf{y}_i) 
       - \boldsymbol\Phi(\mathbf{x}_i,\hat{\mathbf{y}})  \right]$ 
\EndIf
\State $\bar{\mathbf{w}} \gets \bar{\mathbf{w}}+\mathbf{w}$
\EndFor
\EndFor
\State \Return $\bar{\mathbf{w}}/N$
\EndFunction
\end{algorithmic}
\caption{\label{algo-perceptron-train-avg}Estimation des paramètres d'un
  perceptron moyenné}
\end{algorithm}

SGD + ASGD
ASGD

\section{Estimation des paramètres et approximations}

Pour certains types de problèmes ou de représentations, il n'est pas
possible d'évaluer un \ac{dag} de programmation dynamique exhaustivement.
En pratique, les temps de calcul deviennent prohibitifs.
Pour cette raison, on peut souhaiter utiliser une méthode de recherche
approximative en faisceau, y compris lors de l'apprentissage.

Dans le contexte d'un problème d'estimation des paramètres,
l'utilisation d'un faisceau pose un problème au niveau de la procédure
de prédiction (Algorithme  \ref{algo-perceptron-train}, ligne \ref{algoline-pseudoargmax})
Le problème posé par ce type de méthode est que les méthodes en
faisceau renvoient un {\sl pseudo-argmax} qui a pour origine
l'inexactitude de l'algorithme de recherche de solutions.
Cela signifie que $\hat{\mathbf{y}}$ est potentiellement sous-optimal,
ce qui fausse la mise à jour (ligne \ref{algoline-update}) et peut
causer la divergence de la procédure d'estimation.

\paragraph{Mise à jour d'un modèle à large marge}
Pour comprendre le problème, on commence par reformuler la procédure 
de mise à jour dans le cas exact (sans utiliser un faisceau). Notons  $\mathbf{y}^*$ la séquence
incorrecte à laquelle le modèle attribue le meilleur score, c'est-à-dire~:
\begin{displaymath}
\mathbf{y}^* = \mathop{\text{argmax}}_{\mathbf{y} \in
  \mathbf{Y}\backslash \{\mathbf{y}\}} \mathbf{w}^T \boldsymbol\Phi(\mathbf{x},\mathbf{y})
\end{displaymath}
Il y a nécessairement mise à jour lorsque le score de la meilleure séquence
incorrecte est supérieur au score de la séquence correcte~: $\Psi(\mathbf{y}^*) \geq \Psi(\mathbf{y})$.
Lorsque $\Psi(\mathbf{y}^*) <\Psi(\mathbf{y})$ il n'y a pas de mise à
jour. Cette reformulation se jsutifie par le fait que le perceptron
peut être vu comme un cas particulier de modèle à large marge
(Chapitre XXX). 

\paragraph{Généralisation aux méthodes en faisceau}
Dans un contexte où on utilise un faisceau ($\mathbf{Y}' \subsetneqq \mathbf{Y}$), la meilleure prédiction dans le
beam $\tilde{\mathbf{y}} = \text{argmax}_{\mathbf{y} \in \mathbf{Y'}}
\mathbf{w}^T \boldsymbol\Phi(\mathbf{x},\mathbf{y})$ ne correspond pas nécessairement à
la meilleure séquence optimale $\hat{\mathbf{y}} = \text{argmax}_{\mathbf{y} \in \mathbf{Y}}
\mathbf{w}^T \boldsymbol\Phi(\mathbf{x},\mathbf{y})$ qui a pu être écartée du faisceau prématurément.  
Le cas suivant devient désormais possible~:
\begin{displaymath}
\Psi(\tilde{\mathbf{y}}) < \Psi(\mathbf{y}) \text{ alors que } \hat{\mathbf{y}} = \mathbf{y}
\end{displaymath}
Une telle configuration entraine la mise à jour des paramètres du perceptron. Dans
ce cas on parle de mise à jour invalide. Il a été démontré
\cite{huang-2012} qu'une mise à jour valide respecte nécessairement la
condition suivante~: 
\begin{displaymath}
\Psi(\tilde{\mathbf{y}}_{1\ldots k}^*) > \Psi(\mathbf{y}_{1\ldots k})
\end{displaymath}
où $\tilde{\mathbf{y}}_{1\ldots k}^*$ dénote la sous séquence préfixe
de tags incorrecte de meilleur score dans le beam et  $\mathbf{y}_{1\ldots k}$
dénote une sous séquence préfixe de tags de référence.
Si cette condition est respectée, la convergence de la procédure d'estimation des paramètres
est garantie. On peut remarquer que cette condition revient à
généraliser le déclenchement de la mise à jour pour les modèles à
large marge au cas des sous-séquences.

Dans la pratique, il est courant depuis \cite{collins-2004} 
de réaliser la mise à jour dès que la séquence de référence sort du
beam pendant l'étape de parsing.
C'est ce qu'on appelle la mise à jour rapide (\kw{early update}).
D'autres méthodes sont possibles. Par exemple, en définissant la marge d'erreur
$\Delta_k =  \Psi(\tilde{\mathbf{y}}_{1\ldots k}^*) -
\Psi(\mathbf{y}_{1\ldots k})$, et en sélectionnant l'indice $k =
\text{argmax}_{1\leq k \leq m} \Delta_k$ on obtient la mise à jour
dite à \kw{violation maximale}. 

{\bf Dire que c'est utilisé par les systèmes de transitions qui
  utilisent un historique très riche}



\chapter{Champs conditionnels aléatoires}

\section{Généralisation des modèles logistiques}

Les modèles de champs conditionnels aléatoires \ac{crf}
sont des modèle qui généralisent les modèles de régression logistique multinomiale au cas des données structurées.
Dans ce cours, on  donne une présentation pour la modélisation de séquences, ce qui est le cas d'usage le plus courant.

On se rappelle qu'un modèle de régression logistique multinomiale prédit une donnée $y$ à partir de variables observées $\mathbf{x}$ de la manière suivante~:
\begin{equation}
\label{eq-logistic-base}
P(Y = y \,|\, \mathbf{x},\mathbf{w}) = \frac{\text{exp}(\mathbf{w}^T \cdot \boldsymbol\Phi(\mathbf{x},y))}{\sum_{y'\in Y}\text{exp}(\mathbf{w}^T \cdot \boldsymbol\Phi(\mathbf{x},y'))}
\end{equation}
Le numérateur représente un score $\psi(y) \geq 0$~: la fonction exponentielle transforme toute valeur réelle en  réel positif. 

Comme chaque classe $y\in Y$ reçoit un score $\psi(y)$,
le dénominateur ne dit rien d'autre qu'un score se transforme en probabilité en le divisant par la somme totale des scores pour toutes les classes. Le dénominateur est parfois appelé constante de normalisation.

Un \ac{crf} linéaire n'est rien d'autre qu'un modèle de régression logistique multinomiale dont la variable $Y$ à prédire est un ensemble de séquences. Dans ce contexte, la difficulté est que le nombre de séquences possibles de tags (ou plus généralement de symboles) croit exponentiellement en fonction de la longueur de la séquence à prédire.
Ainsi il devient rapidement très difficile de réutiliser naïvement le modèle de régression logistique multinomiale (équation \ref{eq-logistic-base}), car le calcul de la constante de normalisation devient très vite ingérable.

Toute l'idée de \ac{crf} c'est de permettre la décomposition du calcul du score d'une séquence de telle sorte que l'on puisse réutiliser les méthodes de programmation dynamique notamment introduites dans les cours précédents pour réaliser les calculs dans des temps raisonnables (complexité polynomiale).  Ainsi une séquence de tags $\mathbf{y} = y_1 \ldots y_m$ sera prédite par un \ac{crf} à l'aide de la formule suivante~:
\begin{equation}
\label{eq-crf-predict}
P(\mathbf{Y} = \mathbf{y} \,|\, \mathbf{x},\mathbf{w}) = \frac{\text{exp}\left(\sum_{i=1}^m \mathbf{w}^T \cdot \boldsymbol\Phi(\mathbf{x},y_{i-1},y_i)\right)}
{\sum_{\mathbf{y}'\in \mathbf{Y}}
\text{exp}\left(\sum_{i=1}^m \mathbf{w}^T \cdot \boldsymbol\Phi(\mathbf{x},y^{'}_{i-1},y^{'}_i)\right)}
\end{equation}
On voit que dans cette formulation le score global d'une séquence se décompose en une somme de scores locaux.  Il ne s'agit de rien d'autre que d'imposer une décomposition du calcul d'un produit scalaire destiné à évaluer une séquence (un produit scalaire est une grosse addition de toute façon).

<DESSIN QUI ILLUSTRE QU'UNE SEQUENCE EST UNE SOMME DE SCORES>

On va évidemment tirer parti de cette propriété pour exprimer des algorithmes qui partagent des sous parties de calculs efficacement\ldots  On traite en priorité l'algorithmique des deux problèmes d'inférence suivants~:
\begin{itemize}
\item Prédire la séquence de tags la plus probable $\hat{\mathbf{y}}$ pour une séquence de mots $\mathbf{x}$, c'est-à-dire résoudre le problème suivant~:
\begin{equation}
\label{eq-crf-argmax}
\hat{\mathbf{y}} =  \mathop{\text{argmax}}_{\mathbf{y}\in \mathbf{Y}}
\, P(\mathbf{Y}=\mathbf{y} | \mathbf{x},\mathbf{w})
\end{equation}
\item Estimation par maximum de vraisemblance conditionnelle des paramètres d'un modèle dans un contexte d'apprentissage supervisé.
La résolution de ce problème nous fera résoudre par effet de bord le sous-problème de calcul de la probabilité d'une assignation de tags $P(\mathbf{Y}=\mathbf{y} | \mathbf{x},\mathbf{w})$.
\end{itemize}

\begin{exo}[fonction exponentielle]
Faire un graphique avec la librairie graphique de votre choix de la fonction $x\mapsto e^x $ sur l'intervalle réelle $]-\infty,+\infty[$
\end{exo}

\section{Recherche de la séquence de tags la plus probable}

\paragraph{La solution du paresseux}
La solution la plus efficace (et à utiliser en pratique) au problème (\ref{eq-crf-argmax}) est celle du paresseux.  Il suffit de remarquer que les fonctions exponentielles utilisées en (\ref{eq-crf-predict})  n'ont pas d'autre fonction que de normaliser les scores de produits scalaires pour obtenir des probabilités et que la normalisation
ne change pas la valeur du maximum. Par conséquent, chercher la solution de~:
\begin{equation}
\hat{\mathbf{y}} =  \mathop{\text{argmax}}_{\mathbf{y}\in \mathbf{Y}}
\, \sum_{i=1}^m \mathbf{w}^T \cdot \boldsymbol\Phi(\mathbf{x},y_{i-1},y_i)
\end{equation}
à la place de (\ref{eq-crf-argmax}) résoud le problème. La solution du paresseux revient donc à réutiliser la méthode de résolution déjà présentée pour le modèle du perceptron global (algorithme de Viterbi). 

\paragraph{La solution par décomposition explicite du score}
Le détail de l'autre solution présentée ici (à ne pas utiliser en pratique) permet de mieux comprendre comment le score d'un \ac{crf} se décompose.
L'idée est de reformuler le score non normalisé d'une séquence par un produit comme suit~: 
\begin{displaymath}
\text{exp}\left(\sum_{i=1}^m \mathbf{w}^T \cdot \boldsymbol\Phi(\mathbf{x},y_{i-1},y_i)\right)
\end{displaymath}
devient~:
\begin{displaymath}
\prod_{i=1}^m \text{exp}\left(\mathbf{w}^T \cdot \boldsymbol\Phi(\mathbf{x},y_{i-1},y_i)\right)
\end{displaymath}
On peut donc remarquer qu'on peut reformuler le score d'une séquence par un produit de réels strictement positifs appelés potentiels (et notés $\psi(\mathbf{x},y_{i-1},y_i)$). La conséquence est que l'algorithme de Viterbi pour \ac{crf} a exactement la même forme que pour \ac{hmm}~:
les scores de séquences sont des produits de potentiels et les séquences sont comparées par la fonction maximum. Plus généralement, la reformulation de (\ref{eq-crf-predict}) par 
\begin{equation}
P(\mathbf{Y} = \mathbf{y} \,|\, \mathbf{x},\mathbf{w}) = \frac{\prod_{i=1}^m\text{exp}\left( \mathbf{w}^T \cdot \boldsymbol\Phi(\mathbf{x},y_{i-1},y_i)\right)}
{\sum_{\mathbf{y}'\in \mathbf{Y}}
\prod_{i=1}^m \text{exp}\left(\mathbf{w}^T \cdot \boldsymbol\Phi(\mathbf{x},y^{'}_{i-1},y^{'}_i)\right)}
\end{equation}
permet de tirer parti de toute l'algorithmique de programmation dynamique déjà développée pour \ac{hmm}.

\section{\`A la découverte des \ac{dag}s de programmation dynamique}

On se propose dans cette section d'étudier par l'exemple quelques propriétés des \ac{dags}
de programmation dynamique qui seront déterminantes pour résoudre le problème d'estimation des paramètres d'un \ac{crf}. 
\begin{center}
\begin{tikzpicture}[xscale=2,yscale=3]
\node[shape=circle,draw=black,double=red] (S) at (0,0.5) {S};
\node[shape=circle,draw=black,double=red] (E) at (3,0.5) {E};
\node[shape=circle,draw=black] (1) at (1,0) {A};
\node[shape=circle,draw=black] (2) at (1,1) {B};
\node[shape=circle,draw=black] (3) at (2,0) {A};
\node[shape=circle,draw=black] (4) at (2,1) {B};

\draw [->,opacity=0.75](S) -- (1) node[midway,fill=white]{5};
\draw [->,opacity=0.75](S) -- (2) node[midway,fill=white]{2};
\draw [->,opacity=0.75](1) -- (3) node[midway,fill=white]{3};
\draw [->,opacity=0.75](1) -- (4) node[near end,fill=white]{4};
\draw [->,opacity=0.75](2) -- (3) node[near end,fill=white]{7};
\draw [->,opacity=0.75](2) -- (4) node[midway,fill=white]{4};
\draw [->,opacity=0.75](3) -- (E) node[midway,fill=white]{2};
\draw [->,opacity=0.75](4) -- (E) node[midway,fill=white]{3};
\end{tikzpicture}
\end{center}
Le \ac{dag} ci-dessus va nous servir d'exemple de départ. Il encode un problème qui correspond à  probabiliser toutes les séquences possibles de 2 tags, pris dans le jeu de tags $Y=\{A,B\}$, pour une séquence de deux mots. On ajoute un état source unique $S$ et un état de but à atteindre $E$. La pondération des arcs correspond à des valeurs possibles pour des potentiels $\psi(\mathbf{x},y_{i-1},y_{i})$ strictement positifs.
 
En termes de notations, on notera $s_i$ un noeud du \ac{dag} où $s\in Y$ est un tag et $i$ sa position. Chaque chemin $\pi = s_1,s_2\ldots s_{k-1},s_k$ dans le \ac{dag} a un score noté $\sigma(\pi)$.  

%\item On a $\sigma(\pi)$, score d'un chemin.
%\item On a $\alpha(s_i)$, somme des scores de tous les chemins qui mènent à $s_i$ depuis l'origine.
%\item On a $\beta(s_i)$, somme des scores de tous les chemins qui mènent à $s_i$ depuis le but.
%\item $\psi(s_i,s_{i+1})$, score d'un arc


\begin{algorithm}[htbp]
\begin{algorithmic}
\Function{Viterbi}{S,V,s}
\State \Call{TriTopologique}{$S,V,s$}
\State $\delta(s) \gets 1$
\ForAll {$s \in  S$ (suivant ordre topologique)}
\State $\delta(s) \gets 0$
\ForAll {$(s',s) \in AE(s)$}
\State  $\delta(s) \gets \Call{Max}{\delta(s) , \delta(s')  \times \psi(\mathbf{x},s',s) $}
\EndFor
\EndFor
\EndFunction
\end{algorithmic}
\caption{\label{algo-viterbi-crf}Algorithme de Viterbi pour \ac{crf}}
\end{algorithm}
 
\begin{exo}[Viterbi]
Simuler l'exécution de l'algorithme de Viterbi (Algorithme \ref{algo-viterbi-crf}) sur l'exemple illustratif. Quel est le poids du meilleur chemin ? Quel est ce chemin ? 
\end{exo}

\begin{exo}[Viterbi]
Dans la section précédente, on suggère une "solution du paresseux" pour trouver le meilleur chemin dans un \ac{crf}.  L'algorithme \ref{algo-viterbi-crf} est-il directement utilisable dans ce contexte ? Si la réponse est négative, quelles modifications faudrait-il lui apporter ?
\end{exo}




\subsubsection{Algorithme avant} Quelle est la somme des scores qui mènent à un état $s_i$ depuis la source ? C'est la question à laquelle répond l'algorithme avant.
Notons $\alpha(s_i)$ la quantité qui correspond à la somme des scores de tous les chemins qui mènent à $s_i$ depuis la source. Par exemple $\alpha(B_2) = (2\times 4) + (5\times 4) = 28$.


\begin{algorithm}[htbp]
\begin{algorithmic}
\Function{Forward}{S,V,s}
\State \Call{TriTopologique}{$S,V,s$}
\State $\alpha(s) \gets 1$
\ForAll {$s \in  S$ (suivant ordre topologique)}
\State $\alpha(s) \gets 0$
\ForAll {$(s',s) \in AE(s)$}
\State  $\alpha(s) \gets \alpha(s) + (\alpha(s')  \times \psi(\mathbf{x},s',s) ) $
\EndFor
\EndFor
\EndFunction
\end{algorithmic}
\caption{\label{algo-forward}Algorithme Avant}
\end{algorithm}

On peut automatiser ce type de calcul à l'aide de l'algorithme avant qui est une variante, à demi-anneau près, de l'algorithme de Viterbi. Celle-ci est donnée en algorithme \ref{algo-forward}. La récurrence de cet algorithme est la suivante~: 
\begin{equation}
\label{eq-forward}
\alpha(s_i) = \left\{ 
\begin{array}{ll}
1 & \text{si }  i = 0\\
\sum_{(s',s_i)\in AE(s_i)}  \alpha(s') \times \psi(\mathbf{x},s',s_i)&\text{sinon}
\end{array}
\right.
\end{equation}
On peut remarquer que la quantité $\alpha(E)$ correspond au facteur de normalisation $Z$, c'est-à-dire la somme des scores de tous les chemins qui mènent de la source jusqu'à la destination (toutes les séquences de tags possibles). Autrement dit, l'algorithme avant permet de résoudre en temps polynomial le problème de sommation de scores pour un nombre exponentiel de séquences de tags. Formellement on a donc que~: 
\begin{displaymath}
\alpha(s_i) = \sum_{y_1\ldots y_i \in \mathbf{Y^i}}\prod_{j=1}^{j=i} \psi(\mathbf{x},y_{j-1},y_j)
\end{displaymath}
et pour la cas spécifique des séquences complètes~: 
\begin{displaymath}
\alpha(s_{m+1}) = Z = \sum_{\mathbf{y}\in \mathbf{Y}}\prod_{j=1}^{j=m} \psi(\mathbf{x},y_{j-1},y_j)
\end{displaymath}


\begin{exo}[Probabilité d'une séquence]
Utiliser les propriétés de l'algorithme avant pour 
calculer $P(S_0,B_1,A_2,E_3)$ la probabilité de la séquence $S,B,A,E$ dans le \ac{dag} exemple.
\end{exo}

\begin{exo}[Probabilité de toutes les séquences]
Calculer la probabilité de tous les chemins qui mènent de la source à la destination dans le \ac{dag} exemple. Vérifier que ces probabilités somment à 1 et que la séquence qui a la plus haute probabilité correspond à celle que vous avez trouvé avec l'algorithme de Viterbi.
\end{exo}

\subsubsection{Algorithme arrière} Quelle est la somme des scores qui mènent à un état $s_i$ depuis la destination ?
C'est la question à laquelle répond l'algorithme arrière.
On notera $\beta(s_i)$ la quantité qui correspond à la somme des scores de tous les chemins qui mènent à $s_i$ depuis la destination. Par exemple $\beta(B_1) = (2\times 3) + (3\times 4) = 18$. Il s'agit essentiellement d'une variante miroir de l'algorithme avant. La récurrence est la suivante~:
\begin{equation}
\label{eq-backward}
\beta(s_i) = \left\{ 
\begin{array}{ll}
1 & \text{si }  i = m+1\\
\sum_{(s_i,s')\in AS(s_i)}  \beta(s') \times \psi(\mathbf{x},s_i,s')&\text{sinon}
\end{array}
\right.
\end{equation}
En tant que tel cet algorithme arrière n'a pas beaucoup d'intérêt. C'est en combinaison avec l'algorithme avant que l'on peut faire émerger son utilité.

\begin{exo}[Pseudo-code]
Donner un pseudo code pour l'algorithme arrière.
\end{exo}

\subsubsection{Combiner les quantités avant et arrière}
Utilisées en combinaison, les quantités $\alpha(s_i)$ et $\beta(s_i)$ permettent de donner des probabilités à des sous-chemins dans un \ac{dag}.

\begin{figure}[htbp]
\begin{center}
\begin{tikzpicture}[xscale=2,yscale=3]
\def\x{0.0}
\def\y{0.2}
\node[shape=circle,draw=black,double=red] (S) at (0,0.5) {S};
\node[shape=circle,draw=black,double=red] (E) at (4,0.5) {E};
\node[shape=circle,draw=black] (1) at (1,0) {A};
\node[shape=circle,draw=black] (2) at (1,1) {B};
\node[shape=circle,draw=black] (3) at (2,0) {A};
\node[shape=circle,draw=black] (4) at (2,1) {B};
\node[shape=circle,draw=black] (5) at (3,0) {A};
\node[shape=circle,draw=black] (6) at (3,1) {B};

\draw [->,opacity=0.75](S) -- (1) node[midway,fill=white]{5};
\draw [->,opacity=0.75](S) -- (2) node[midway,fill=white]{2};
\draw [->,opacity=0.75](1) -- (3) node[midway,fill=white]{3};
\draw [->,opacity=0.75](1) -- (4) node[near end,fill=white]{4};
\draw [->,opacity=0.75](2) -- (3) node[near end,fill=white]{7};
\draw [->,opacity=0.75](2) -- (4) node[midway,fill=white]{4};
\draw [->,opacity=0.75](3) -- (5) node[midway,fill=white]{2};
\draw [->,opacity=0.75](3) -- (6) node[near end,fill=white]{3};
\draw [->,opacity=0.75](4) -- (5) node[near end,fill=white]{2};
\draw [->,opacity=0.75](4) -- (6) node[midway,fill=white]{1};
\draw [->,opacity=0.75](5) -- (E) node[midway,fill=white]{2};
\draw [->,opacity=0.75](6) -- (E) node[midway,fill=white]{3};

%alphas
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (0+\x,0.5+\y){1};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (4+\x,0.5+\y){573};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (1+\x,0+\y){5};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (1+\x,1+\y){2};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (2+\x,0+\y){29};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (2+\x,1+\y){28};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (3+\x,0+\y){114};
\node [shape=rectangle,fill=blue,opacity=0.3,draw=black] at (3+\x,1+\y){115};
%betas
\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (0+\x,0.5-\y){573};
\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (4+\x,0.5-\y){1};
\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (1+\x,0-\y){67};
\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (1+\x,1-\y){119};
\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (2+\x,0-\y){13};
\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (2+\x,1-\y){7};
\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (3+\x,0-\y){2};
\node [shape=rectangle,fill=red,opacity=0.3,draw=black] at (3+\x,1-\y){3};
\end{tikzpicture}
\end{center}
\caption{\label{fig-fb-trellis}Treillis de programmation dynamique annoté par $\alpha$ et $\beta$}
\end{figure}

L'exemple donné en figure \ref{fig-fb-trellis} illustre les quantités $\alpha(s_i)$, notées en bleu sur chaque noeud, et les quantités $\beta(s_i)$ sont notées en rouge.
On peut commencer par observer que la  quantité $\alpha(E_4) = 573$ correspond au facteur $Z$. 
On obtient la probabilité d'un chemin (d'une séquence de tags) comme par exemple le chemin $S_0,A_1,B_2,B_3,E_4$ en réalisant la division suivante~:
\begin{displaymath}
P(S_0,A_1,B_2,B_3,E_4) = \frac{5\times 4\times 1\times 3}{573} = \frac{60}{573}
\end{displaymath}
En utilisant la quantité $\alpha(s_i)$, on peut déterminer la probabilité d'un séquence de tags qui termine par $B,B,E$ de la manière suivante~:
\begin{displaymath}
P(\lhd,B_2,B_3,E_4) = \frac{\alpha(B_2)\times \psi(\mathbf{x},B_2,B_3)\times\psi(\mathbf{x},B_3,E_4)}{Z} = \frac{28\times 1\times 3}{573} = \frac{84}{573} 
\end{displaymath}
En continuant le raisonnement on peut calculer la probabilité de suivre une transition (par exemple $A_1,B_2$ représente la probabilité de tagguer le premier mot $A$ et le second mot $B$) en utilisant les quantités $\alpha(s_i)$ et $\beta(s_i)$~:
\begin{displaymath}
P(\lhd,A_1,B_2,\rhd) = \frac{\alpha(A_1)\times \psi(\mathbf{x},A_1,B_2)\times \beta(B_2)}{Z} = \frac{5\times 4 \times 7}{543}=\frac{140}{543}
\end{displaymath}
En résumé, et comme illustré dans les exercices qui suivent, on peut en réalité transformer un graphe de programmation dynamique en calculette.

Ce dernier exemple introduit une quantité clé qui est réutilisée par la méthode d'estimation des paramètres par descente de gradient qui est~:
\begin{equation}
P(\lhd,s_i,s_{i+1},\rhd | \mathbf{x};\mathbf{w}) = 
\frac{\alpha(s_i)\times \psi(\mathbf{x},s_i,s_{i+1}) \times \beta(s_{i+1})}
{Z}
\end{equation}
Celle-ci correspond à la probabilité de suivre une transition entre deux tags consécutifs. Utiliser les quantités avant et arrière pour calculer ces probabilités de transition, c'est utiliser l'\kw{algorithme avant/arrière}. Formellement, on peut remarquer que $P(\lhd,s_i,s_{i+1},\rhd | \mathbf{x})$ correspond à :
\begin{eqnarray}
P(\lhd,s_i,s_{i+1},\rhd | \mathbf{x})&=& \frac{1}{Z} \sum_{y_1\ldots y_{i-1}}\prod_{j=1}^{j={i-1}} \psi(\mathbf{x},y_{i-1},y_{i})\\
&\times &\psi(\mathbf{x},y_{i-1},y_i)\\
&\times &\sum_{y_i\ldots y_m}\prod_{j={i+1}}^{j=m} \psi(\mathbf{x},y_{j-1},y_{j})
\end{eqnarray}


\begin{exo}
\`A partir de la figure \ref{fig-fb-trellis},
donner la probabilité que le second mot soit taggué $B$, c'est-à-dire, $P(\lhd,B_2,\rhd)$.
\end{exo}

\begin{exo}
Observer que $P(\lhd,B_2,\rhd) + P(\lhd,A_2,\rhd) = 1$
à partir de la figure \ref{fig-fb-trellis}.
Expliquer informellement pourquoi.
\end{exo}

\section{Estimation des paramètres}

L'estimation des paramètres d'un \ac{crf} consiste à déterminer les valeurs du vecteur de paramètres $\mathbf{w}$ à partir d'un corpus annoté.

On suppose qu'un corpus annoté $C =\mathop{(\mathbf{x}_i,\mathbf{y}_i)\}}_{i=1}^N$ est un exemplaire de $N$ phrases. Chaque exemple annoté est un couple $(\mathbf{x}_i,\mathbf{y}_i)$ qui représente une séquence de mots $\mathbf{x}=x_1\ldots x_m$ et une séquence de tags de référence $\mathbf{y} = y_1\ldots y_m$ de même longueur.

Comme pour la régression logistique multinomiale,
on présente ici l'estimation des paramètres par maximum de (log-) vraisemblance conditionnelle. 
\begin{equation}
L(\mathbf{w}) = \sum_{i=1}^N \log P(\mathbf{y}_i | \mathbf{x}_i;\mathbf{w})
\end{equation}
Autrement dit on cherche à résoudre le problème d'optimisation suivant~:
\begin{equation}
\hat{\mathbf{w}} =  \mathop{\text{argmax}}_{\mathbf{w}\in\mathbb{R}^d} \sum_{i=1}^N \log P(\mathbf{y}_i | \mathbf{x}_i;\mathbf{w})
\end{equation}
En substituant la probabilité $P(\mathbf{y}_i | \mathbf{x}_i;\mathbf{w})$ par sa définition en équation (\ref{eq-crf-predict}), on optimise~:
\begin{equation}
\hat{\mathbf{w}} =  \mathop{\text{argmax}}_{\mathbf{w}\in\mathbb{R}^d} \sum_{i=1}^N \log\frac{\text{exp}\left(\sum_{i=1}^m \mathbf{w}^T \cdot \boldsymbol\Phi(\mathbf{x},y_{i-1},y_i)\right)}
{\sum_{\mathbf{y}'\in \mathbf{Y}}
\text{exp}\left(\sum_{i=1}^m \mathbf{w}^T \cdot \boldsymbol\Phi(\mathbf{x},y^{'}_{i-1},y^{'}_i)\right)}
\end{equation}
Les dérivées partielles ont la même allure que pour la régression logistique multinomiale~:
\begin{equation}
\label{eq-crf-derivative}
\frac{\partial L(\mathbf{w})}{\partial w_k} 
= \sum_{i=1}^N C_k(\mathbf{x}_i,\mathbf{y}_i)
- \sum_{i=1}^N \sum_{\mathbf{y}\in \mathbf{Y}} P(\mathbf{y}|\mathbf{x}_i,\mathbf{w}) C_k(\mathbf{x}_i,\mathbf{y})
\end{equation}
où l'abbréviation $C_k(\mathbf{x},\mathbf{y})$
représente le comptage de la feature $\phi_k$
dans une séquence de référence, c'est-à-dire~:
\begin{displaymath}
C_k(\mathbf{x}_i,\mathbf{y}_i) = \sum_{j=1}^m \phi_k(\mathbf{x}_i,y_{j-1}^i,y_j^i)
\end{displaymath}
Le calcul du premier terme en (\ref{eq-crf-derivative}) consiste à compter les occurrences de $\phi_k$ dans l'ensemble des séquences du corpus de référence.

En ce qui concerne le second terme en (\ref{eq-crf-derivative}), il faut compter les occurrences de $\phi_k$ 
--~dans toutes les séquence de tags possibles~-- en pondérant chaque occurrence par la probabilité de la séquence de tags dans laquelle elle apparait. 
Naïvement, ce calcul demande d'énumérer
l'ensemble exponentiel $\mathbf{Y}$ 
de toutes les séquences de tags $\mathbf{y}\in\mathbf{Y}$ possibles pour chaque exemple du jeu de données.

Le développement qui suit consiste à montrer comment utiliser les techniques de programmation dynamique présentées précédemment pour réaliser ce calcul de manière efficace.  Le second terme de la formule (\ref{eq-crf-derivative}) nous dit que pour chaque exemple dans les données il faut calculer~:
\begin{align}
&\sum_{\mathbf{y}\in \mathbf{Y}} P(\mathbf{y}|\mathbf{x},\mathbf{w}) \sum_{j=1}^m \phi_k(\mathbf{x},y_{j-1},y_j)\\
&=\sum_{\mathbf{y}\in \mathbf{Y}} \sum_{j=1}^m P(\mathbf{y}|\mathbf{x},\mathbf{w})  \phi_k(\mathbf{x},y_{j-1},y_j)\\
&= \sum_{j=1}^m \sum_{\mathbf{y}\in \mathbf{Y}} P(\mathbf{y}|\mathbf{x},\mathbf{w})  \phi_k(\mathbf{x},y_{j-1},y_j)\\
&=  \sum_{j=1}^m \sum_{y_{j-1}}\sum_{y_j} P(\lhd,y_{j-1},y_j,\rhd|\mathbf{x},\mathbf{w})  \phi_k(\mathbf{x},y_{j-1},y_j)
\end{align}
Au terme de cette reformulation, l'évaluation du second terme revient à compter les occurrences de la feature $\phi_k$ --~pondérées par les probabilités de transitions où elles apparaissent~-- dans le \ac{dag} de programmation dynamique, et ce pour l'ensemble des exemples du jeu de données.




{\color{red} Développement un peu sloppy en l'état, voir par ex.
\url{http://perso.telecom-paristech.fr/~essid/teach/CRF_tutorial_ISMIR-2013.pdf}
pour des détails supplémentaires.}


\section{Fonctions features et potentiels}


\chapter{Approximations par modèles locaux}

Motivation = réduire temps d'entrainement.

\section{Modèles markoviens à maximum d'entropie}
\section{Perceptrons locaux}
\section{Modèles à oracles dynamiques}


\appendix
\chapter{Représentations pour les modèles creux}
\section{Représentation des matrices de poids}

\subsection{Représentation explicite de la matrice de poids}

Pour des modèles multiclasses à features,
l'opération primitive consiste à scorer chaque classe de l'ensemble $\{a,b,c\ldots\}$ à l'aide du vecteur creux de features $\boldsymbol\Phi(x)$ et du vecteur de poids $\mathbf{w}_i$ correspondant à la classe $i$. Ainsi le score de la classe $i$ sera calculé comme suit~:
\begin{displaymath}
s_i =  \mathbf{w}_i \cdot \boldsymbol\Phi(x)
\end{displaymath}
Comme on souhaite en général donner un score à toutes les classes, on peut organiser les poids en matrice $\mathbf{W}$ dont chaque ligne représente les poids destinés à donner la pondération spécifique à une classe donnée, de telle sorte que le vecteur de scores $\mathbf{s} = \mathbf{W}\cdot \boldsymbol\Phi(x)$ se calcule en une opération.
On illustre cette représentation ci-dessous~:
\begin{center}
\begin{tikzpicture}
\matrix(S)[matrix of math nodes,left delimiter  = {[}, right delimiter = {]} ] at (0,0)
{
	s_a\\s_b\\s_c\\
};
\node[shape=circle,draw=white] (X) at (1.25,0) {=};
\matrix(A)[matrix of math nodes,left delimiter  = {[}, right delimiter = {]}] at (4,0)
{
 w_{a1} & w_{a2} & \ldots & w_{ap}\\
 w_{b1} & w_{b2} & \ldots & w_{bp}\\
 w_{c1} & w_{c2} & \ldots & w_{cp}\\
};
\matrix(V)[matrix of math nodes,left delimiter  = {[}, right delimiter = {]}] at (8,0)
{
 \phi_{1}(x) \\ \phi_{2}(x) \\ \vdots \\ \phi_{p}(x)\\
};
\end{tikzpicture}
\end{center}
On aura alors que le score $s_i$ de la classe $i$ sera donné en position $i$ dans $\mathbf{s}$.

Il faut remarquer que le vecteur $\boldsymbol\Phi(x) = \phi_1(x) \ldots \phi_p(x)$ est valué par des fonctions features qui valent 0 dans la plupart des cas et 1 dans de rares cas. 
Par  conséquent $\boldsymbol\Phi(x)$ est un vecteur creux.



\subsection{Représentation de la matrice de poids par un vecteur}

{\bf dire que ce cas s'applique aux problèmes structurés où
  l'ensemble $Y$ est très large ou infini (récursivement énumérable)}


Dans un contexte ou le vecteur $\boldsymbol\Phi(x)$
est un vecteur creux de très grande dimensionnalité, 
on utilise couramment une représentation alternative qui consiste à coder la matrice $\mathbf{W}$ dans un vecteur $\mathbf{w}$ unique. Dans ce contexte le vecteur 
de features sera valué à 1 uniquement pour certaines features de la forme $\phi_{y1},\phi_{y2}\ldots \phi_{yp}$ qui correspondent aux poids de la classe $y$ pour la feature $i$. Dans ce contexte le vecteur de features est noté $\boldsymbol\Phi(x,y)$ où $y$ indique la classe pour laquelle on calcule le score.
Ainsi pour calculer le score $s_a$ de la classe $a$,  on réalisera un produit scalaire avec une représentation du type~:
\begin{center}
\begin{tikzpicture}
\matrix(W)[matrix of math nodes,left delimiter  = {[}, right delimiter = {]}] at (-1,0)
{
 w_{a1} & w_{a2} & \ldots & w_{ap}& w_{b1} & w_{b2} & \ldots & w_{bp}&  w_{c1} & w_{c2} & \ldots & w_{cp}\\
};
\matrix(V)[matrix of math nodes,left delimiter  = {[}, right delimiter = {]} ]at (5.5,0)
{
 \phi_{a1}(x) \\ \phi_{a2}(x) \\ \vdots \\ \phi_{ap}(x)\\
};
\end{tikzpicture}
\end{center}
où seules certaines features de la forme $\phi_{a\cdot}$ sont valuées à 1 alors que les features de la forme $\phi_{b\cdot}$ et $\phi_{c\cdot}$ sont implicitement valuées à 0.

\section{Exemple de structure de données}

Une large classe de modèles d'apprentissage utilisés en \ac{tal}
fait intervenir des modèles creux. Il s'agit de modèles où le vecteur 
$\boldsymbol\Phi(x,y) \in \{0,1\}^d$ est un vecteur booléen de très grande dimension.
Les scores calculés par ces modèles sont essentiellement des produits scalaires de la forme :
\begin{displaymath}
s = \mathbf{w}\cdot \boldsymbol\Phi(x,y)
\end{displaymath}
où $\mathbf{w} \in \mathbb{R}^d$ est un vecteur de poids de dimension identique à $\boldsymbol\Phi(x,y)$. Dans ce contexte l'évaluation d'un produit scalaire revient à sommer les poids des features actives (mises à 1). 

Les autres opérations importantes est la mise à jour des poids lors de la descente de gradient, ce qui demande d'additionner (ou de soustraire) le vecteur de poids courant avec le vecteur gradient.

La structure de données ci-dessous exprimée en python apporte une fonction de produit scalaire ({\sl dot}) à partir des valeurs discrètes de $(x,y)$. Pour les mises à jour, elle propose une fonction de codage {\sl code$\_$phi} qui code une liste de valeurs discrète $x$ et renvoie $\boldsymbol\Phi(x)$ ainsi que des opérateurs arithmétiques de vecteurs et de scalaires ($+,-,\times, / , +=$).
Celle-ci peut-être étendue à d'autres usages, par exemple la surcharge d'opérateurs arithmétiques pour vecteurs et scalaires peut être complétée.

La structure de donnée reste néanmoins exprimée dans le but pédagogique de rester facile à lire et à modifier mais réalise la plupart des opérations de manière peu efficace.  Pour privilégier l'efficacité, il est suggéré de s'appuyer sur des librairies numériques qui supportent les opérations creuses ou de réaliser des interfaces avec du code {\sl C} ou {\sl C++} spécialisé pour réaliser les opérations sur des vecteurs creux.


\begin{minted}{python}
from collections import defaultdict

class SparseWeightVector:

    def  __init__(self):
    
        self.weights = defaultdict(int)   

    def __call__(self,x_key,y_key):
        """
        This returns the weight of a feature couple (x,y)
        Enables an  x = w('a','b') syntax.
        
        @param x_key: a tuple of observed values
        @param y_key: a string being a class name
        @return : the weight of this feature
        """
        return self.weights[(x_key,y_key)]

    def dot(self,xvec_keys,y_key):
        """
        This computes the dot product : w . Phi(x,y).
        Phi(x,y) is implicitly  generated by the function given (x,y)
        @param xvec_keys: a list (vector) of x values
        @param y_key    : a y class name
        @return  w . Phi(x,y)
        """
        return sum([self.weights[(x_key,y_key)] for x_key in xvec_keys])
        
    @staticmethod
    def code_phi(xvec_keys,ykey):
        """
        Explictly generates a sparse boolean Phi(x,y) vector from (x,y) values
        @param xvec_keys:  a list of symbols
        @param ykey: a y class name
        """
        w = SparseWeightVector()
        for xkey in xvec_keys:
            w[(xkey,ykey)] = 1.0
        return w

    def __getitem__(self,key):
        """
        This returns the weight of feature couple (x,y) given as value.
        Enables the 'x = w[]' syntax.	
        
        @param key: a couple (x,y) of observed and class value
        @return : the weight of this feature
        """
        return self.weights[tuple(key)]

    def __setitem__(self,key,value):
        """
        This sets the weight of a feature couple (x,y) given as key.
        Enables the 'w[] = ' syntax.	
        @param key:   a couple (x,y) of observed value and class value
        @param value: a real
        """
        self.weights[key] = value

    def __add__(self,other):
	    """
        Vector addition
        """
        weights =  self.weights.copy() 
        for key,value in other.weights.items() :
            weights[key] += value
        w = SparseWeightVector()
        w.weights = weights
        return w
        
    def __sub__(self,other):
    	"""
        Vector substraction
        """
        weights =  self.weights.copy() 
        for key,value in other.weights.items() :
            weights[key] -= value
        w = SparseWeightVector()
        w.weights = weights
        return w
        
    def __mul__(self,scalar):
    	"""
        Scalar multiplication
        """
        weights =  self.weights.copy() 
        for key,value in self.weights.items() :
            weights[key] *= scalar
        w = SparseWeightVector()
        w.weights = weights
        return w

    def __rmul__(self,scalar):
    	"""
        commutativity of scalar multiplication
        """
        return self.__mul__(scalar)
        
        
    def __truediv__(self,scalar):
    	"""
        Python 3 division '/'
        """
        weights =  self.weights.copy() 
        for key,value in self.weights.items() :
            weights[key] /= scalar
        w = SparseWeightVector()
        w.weights = weights
        return w

    
    def __iadd__(self,other):    
        """
        Sparse Vector inplace addition. Enables the '+=' operator.	
        @param  other: a  SparseVectorModel object
        """
        for key,value in other.weights.items():
            self.weights[key] += value
        return self
    def __isub__(self,other):    
        """
        Sparse Vector inplace substraction. Enables the '-=' operator.	
        @param  other: a  SparseVectorModel object
        """
        for key,value in other.weights.items():
            self.weights[key] -= value
        return self
            
    def load(self,istream):
        """
        Loads a model parameters from a text stream
        @param istream: an opened text stream
        """
        self.weights =  defaultdictionary(int)
        for line in istream:
            fields = line.split() 	
            key,value = tuple(fields[:-1]),float(fields[-1])
            self.weights[key] =  value
        
    def save(self,ostream):
        """
        Saves model parameters to a text stream
        @param ostream: an opened text output stream
		"""
        for key,value in self.weights.items():
            print(' '.join(list(key)+[str(value)]),file=ostream)

    def __str__(self):
        """
        Pretty prints the weights vector on std output.
        May crash if vector is too wide/full
        """
        s = ''
        for key,value in self.weights.items():
            X,Y = key
            if isinstance(X,tuple):
                s += 'phi(%s,%s) = 1 : w = %f\n'%('&'.join(X),Y,value)
            else:
                s += 'phi(%s,%s) = 1 : w = %f\n'%(key,Y,value)
        return s
\end{minted}


\end{document}