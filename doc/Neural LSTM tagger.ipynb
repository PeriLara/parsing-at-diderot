{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Embedding,LSTM, TimeDistributed,Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture des données\n",
    "==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_conll_sentence(istream):\n",
    "    x_seq = []\n",
    "    y_seq = []\n",
    "    line = istream.readline()\n",
    "    while line and not line.isspace():\n",
    "        fields = line.split()\n",
    "        x_seq.append(fields[1])\n",
    "        y_seq.append(fields[3])\n",
    "        line = istream.readline()\n",
    "    return (x_seq,y_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_conll_corpus(filename):\n",
    "    X = []\n",
    "    Y = []\n",
    "    istream = open(filename)\n",
    "    (x,y) = read_conll_sentence(istream)\n",
    "    while x and y:\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "        (x,y) = read_conll_sentence(istream)\n",
    "    istream.close()\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X,Y = read_conll_corpus('../projets-2017-2018/sequoia-corpus.np_conll')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Gutenberg'], ['Cette', 'exposition', 'nous', 'apprend', 'que', 'dès', 'le', 'XIIe', 'siècle', ',', 'à', 'Dammarie-sur-Saulx', ',', 'entre', 'autres', 'sites', ',', 'une', 'industrie', 'métallurgique', 'existait', '.'], ['à_peu_près', 'au', 'même', 'moment', 'que', 'Gutenberg', 'inventait', \"l'\", 'imprimerie', ',', 'Gillet', 'Bonnemire', 'créait', 'en', '1450', 'la', 'première', 'forge', 'à', 'Saint-Dizier', ',', 'à', \"l'\", 'actuel', 'emplacement', 'du', 'CHS', '.']] [['N'], ['D', 'N', 'CL', 'V', 'C', 'P', 'D', 'A', 'N', 'PONCT', 'P', 'N', 'PONCT', 'P', 'A', 'N', 'PONCT', 'D', 'N', 'A', 'V', 'PONCT'], ['ADV', 'P+D', 'A', 'N', 'C', 'N', 'V', 'D', 'N', 'PONCT', 'N', 'N', 'V', 'P', 'N', 'D', 'A', 'N', 'P', 'N', 'PONCT', 'P', 'D', 'A', 'N', 'P+D', 'N', 'PONCT']]\n"
     ]
    }
   ],
   "source": [
    "print(X[:3],Y[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codage des données\n",
    "=================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0, 'ADV': 1, 'P+D': 3, 'ET': 4, 'CL': 5, 'I': 2, 'PRO': 6, 'V': 7, 'PREF': 9, 'A': 10, 'D': 11, 'PONCT': 12, 'P': 13, 'N': 8, 'P+PRO': 14}\n"
     ]
    }
   ],
   "source": [
    "x_set = set([])\n",
    "y_set = set([])\n",
    "init_token = \"__START__\"\n",
    "for x in X:\n",
    "    x_set.update(x)\n",
    "for y in Y:\n",
    "    y_set.update(y)\n",
    "rev_x_codes = [init_token]\n",
    "rev_x_codes.extend(list(x_set))\n",
    "rev_y_codes = list(y_set)\n",
    "x_codes     = dict((x,idx) for idx,x in enumerate(rev_x_codes))\n",
    "y_codes     = dict((y,idx) for idx,y in enumerate(rev_y_codes))\n",
    "print(y_codes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xcodes = []\n",
    "for x in X:\n",
    "    Xcodes.append([x_codes[elt] for elt in x])\n",
    "Ycodes = []\n",
    "for y in Y:\n",
    "    ymat = np.zeros((len(y),len(y_codes)))\n",
    "    for idx,elt in enumerate(y):\n",
    "        ymat[idx,y_codes[elt]] = 1.0\n",
    "    Ycodes.append(ymat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padding et troncation...\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "L = [len(y) for y in Ycodes]\n",
    "mL = int(sum(L)/len(L))\n",
    "print(mL) #longueur moyenne\n",
    "Xcodes = pad_sequences(Xcodes,maxlen=mL)\n",
    "Ycodes = pad_sequences(Ycodes,maxlen=mL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structure du modèle\n",
    "==================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 50)          518950    \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, None, 40)          11360     \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, None, 15)          615       \n",
      "=================================================================\n",
      "Total params: 530,925\n",
      "Trainable params: 530,925\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x_size = len(x_codes)\n",
    "y_size = len(y_codes)\n",
    "embedding_size = 50\n",
    "memory_size    = 20\n",
    "model = Sequential()\n",
    "model.add(Embedding(x_size,embedding_size))\n",
    "model.add(Bidirectional(LSTM(memory_size,return_sequences=True))) #bi-LSTM\n",
    "#model.add(LSTM(memory_size,return_sequences=True))               #simple LSTM\n",
    "model.add(TimeDistributed(Dense(y_size, activation='softmax'))) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descente de gradient\n",
    "===================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3099/3099 [==============================] - 3s - loss: 1.8237 - acc: 0.1910     \n",
      "Epoch 2/20\n",
      "3099/3099 [==============================] - 3s - loss: 1.4649 - acc: 0.2207     \n",
      "Epoch 3/20\n",
      "3099/3099 [==============================] - 3s - loss: 1.2035 - acc: 0.3755     \n",
      "Epoch 4/20\n",
      "3099/3099 [==============================] - 3s - loss: 0.7872 - acc: 0.5373     \n",
      "Epoch 5/20\n",
      "3099/3099 [==============================] - 3s - loss: 0.4764 - acc: 0.6063     \n",
      "Epoch 6/20\n",
      "3099/3099 [==============================] - 3s - loss: 0.3005 - acc: 0.6728     \n",
      "Epoch 7/20\n",
      "3099/3099 [==============================] - 3s - loss: 0.2013 - acc: 0.6953     \n",
      "Epoch 8/20\n",
      "3099/3099 [==============================] - 3s - loss: 0.1456 - acc: 0.7035     \n",
      "Epoch 9/20\n",
      "3099/3099 [==============================] - 3s - loss: 0.1121 - acc: 0.7072     \n",
      "Epoch 10/20\n",
      "3099/3099 [==============================] - 3s - loss: 0.0901 - acc: 0.7091     \n",
      "Epoch 11/20\n",
      "3099/3099 [==============================] - 3s - loss: 0.0748 - acc: 0.7104     \n",
      "Epoch 12/20\n",
      "3099/3099 [==============================] - 3s - loss: 0.0633 - acc: 0.7120     \n",
      "Epoch 13/20\n",
      "3099/3099 [==============================] - 3s - loss: 0.0545 - acc: 0.7141     \n",
      "Epoch 14/20\n",
      "3099/3099 [==============================] - 3s - loss: 0.0476 - acc: 0.7160     \n",
      "Epoch 15/20\n",
      "3099/3099 [==============================] - 3s - loss: 0.0418 - acc: 0.7170     \n",
      "Epoch 16/20\n",
      "3099/3099 [==============================] - 3s - loss: 0.0371 - acc: 0.7183     \n",
      "Epoch 17/20\n",
      "3099/3099 [==============================] - 3s - loss: 0.0331 - acc: 0.7192     \n",
      "Epoch 18/20\n",
      "3099/3099 [==============================] - 3s - loss: 0.0297 - acc: 0.7201     \n",
      "Epoch 19/20\n",
      "3099/3099 [==============================] - 3s - loss: 0.0268 - acc: 0.7205     \n",
      "Epoch 20/20\n",
      "3099/3099 [==============================] - 3s - loss: 0.0243 - acc: 0.7212     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12deea320>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = Adam(lr=0.001)\n",
    "model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(Xcodes,Ycodes,epochs=20,batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prédictions \n",
    "==========="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "(Attention !) Predictions sur les données d'entrainement..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96408757887604291"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def eval_model(x_data,y_ref):\n",
    "    \n",
    "    C = 0\n",
    "    N = 0\n",
    "    for x,yvec in zip(x_data,y_ref):\n",
    "        prob_vec = model.predict(x)\n",
    "        L = [np.argmax(tok_probs) == np.argmax(y) for(y,tok_probs,tok_code) in zip(yvec,prob_vec,x) if tok_code != 0]\n",
    "        C += sum(L)\n",
    "        N += len(L)\n",
    "        \n",
    "    return C/N\n",
    "\n",
    "eval_model(Xcodes,Ycodes)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Illustration (données entrainement parfois tronquées) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gutenberg N\n",
      "\n",
      "exposition N\n",
      "nous CL\n",
      "apprend V\n",
      "que C\n",
      "dès P\n",
      "le D\n",
      "XIIe A\n",
      "siècle N\n",
      ", PONCT\n",
      "à P\n",
      "Dammarie-sur-Saulx N\n",
      ", PONCT\n",
      "entre P\n",
      "autres A\n",
      "sites N\n",
      ", PONCT\n",
      "une D\n",
      "industrie N\n",
      "métallurgique A\n",
      "existait V\n",
      ". PONCT\n",
      "\n",
      "l' D\n",
      "imprimerie N\n",
      ", PONCT\n",
      "Gillet N\n",
      "Bonnemire N\n",
      "créait V\n",
      "en P\n",
      "1450 N\n",
      "la D\n",
      "première A\n",
      "forge N\n",
      "à P\n",
      "Saint-Dizier N\n",
      ", PONCT\n",
      "à P\n",
      "l' D\n",
      "actuel A\n",
      "emplacement N\n",
      "du P+D\n",
      "CHS N\n",
      ". PONCT\n",
      "\n",
      "Ensuite ADV\n",
      ", PONCT\n",
      "fut V\n",
      "installée V\n",
      "une D\n",
      "autre A\n",
      "forge N\n",
      "à P\n",
      "la D\n",
      "Vacquerie N\n",
      ", PONCT\n",
      "à P\n",
      "l' D\n",
      "emplacement N\n",
      "aujourd'_hui ADV\n",
      "de P\n",
      "Cora N\n",
      ". PONCT\n",
      "\n",
      "de P\n",
      "la D\n",
      "Marne PONCT\n",
      "ou_bien C\n",
      "en P\n",
      "aval N\n",
      "de P\n",
      "la D\n",
      "Marne PONCT\n",
      "- PONCT\n",
      ", PONCT\n",
      "une D\n",
      "forge N\n",
      "qui PRO\n",
      "connut V\n",
      "son D\n",
      "apogée N\n",
      "au P+D\n",
      "XIXe A\n",
      "siècle N\n",
      ". PONCT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in Xcodes[:5]:\n",
    "    probs = model.predict(x)\n",
    "    for xc,yprob in zip(x,probs):\n",
    "        if xc != 0:\n",
    "            print(rev_x_codes[xc],rev_y_codes[np.argmax(yprob)])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
